%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[12pt]{article}  % Comment this line out if you need a4paper

\addtolength{\oddsidemargin}{-0.75in}
\addtolength{\evensidemargin}{-0.75in}
\addtolength{\textwidth}{1.5in}

\addtolength{\topmargin}{-1.0in}
\addtolength{\textheight}{1.75in}

\usepackage{pgfplots}
\pgfplotsset{compat=1.16}
\pdfobjcompresslevel=0

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{cite}
\usepackage{url}
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{mathrsfs}
\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}
\usepackage{cuted}
\usepackage{subcaption}

%\usepackage{times} % assumes new font selection scheme installed
\usepackage{setspace}
\usepackage{amssymb,amsmath,amsfonts}
%\usepackage{mathrsfs}
%\usepackage{amsthm}
\usepackage{ntheorem}
\usepackage{booktabs}
\usepackage{makecell}
\let\labelindent\relax
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{esvect}

\usetikzlibrary{circuits}

\usetikzlibrary{intersections} 

\usetikzlibrary{scopes, arrows, fadings, patterns}

\usetikzlibrary{%
	decorations.pathreplacing,%
	decorations.pathmorphing%
}

\usetikzlibrary{positioning}

\usepackage{bm}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{algorithm,algorithmic}  
%\pgfplotsset{compat=1.6}
\usepackage{multirow}

\renewcommand{\labelenumi}{(\arabic{enumi})} % change enumerate env to (1)(2)(3)


\newcommand{\Pb}{{\mathbb{P}}}
\newcommand{\Eb}{{\mathbb{E}}}
\newcommand{\Rb}{{\mathbb{R}}}
\newcommand{\Cb}{{\mathbb{C}}}
\newcommand{\Ib}{{\mathbb{I}}}
\newcommand{\Zb}{{\mathbb{Z}}}

\newcommand{\Fs}{{\mathscr{F}}} % filiteration
\newcommand{\Bs}{{\mathscr{B}}} % Borel set
\newcommand{\Es}{{\mathscr{E}}}


\newcommand{\Ec}{{\mathcal{E}}} %graph vertex edge
\newcommand{\Gc}{{\mathcal{G}}}
\newcommand{\Vc}{{\mathcal{V}}}


\newcommand{\Fc}{{\mathcal{F}}}
\newcommand{\Pc}{{\mathcal{P}}}

\newcommand{\Qc}{{\mathcal{Q}}} 
\newcommand{\Ac}{{\mathcal{A}}}
\newcommand{\Cc}{{\mathcal{C}}}
\newcommand{\Ic}{{\mathcal{I}}}
\newcommand{\Rc}{{\mathcal{R}}}
\newcommand{\Uc}{{\mathcal{U}}}
\newcommand{\Tc}{{\mathcal{T}}}
\newcommand{\Sc}{{\mathcal{S}}}
\newcommand{\Oc}{{\mathcal{O}}}
\newcommand{\Mc}{{\mathcal{M}}}
\newcommand{\Nc}{{\mathcal{N}}}
\newcommand{\Wc}{{\mathcal{W}}}
\newcommand{\Lc}{{\mathcal{L}}}
\newcommand{\Hc}{{\mathcal{H}}}
\newcommand{\Xc}{{\mathcal{X}}}
\newcommand{\Yc}{{\mathcal{Y}}}

\newcommand{\Ss}{{\mathscr{S}}}

\newcommand{\Oi}{{\tilde{O}_i}}
\newcommand{\Gi}{{\tilde{G}_i}}
\newcommand{\Si}{{\tilde{S}_i}}

\newcommand{\ra}{{\rightarrow}}
\newcommand{\ift}{{\infty}}
\newcommand{\ls}{\text{ls}}
\newcommand{\re}{\text{true}}
\DeclareMathOperator{\rs}{{rowspan}}
\DeclareMathOperator{\rank}{{rank}}
\DeclareMathOperator{\sgn}{{sgn}}
\DeclareMathOperator{\diag}{{diag}}
\DeclareMathOperator{\supp}{supp}


\theorembodyfont{\normalfont}
\newtheorem{proposition}{\textbf{Proposition}}
\newtheorem{lemma}{\textbf{Lemma}}
\newtheorem{theorem}{\textbf{Theorem}}
\newtheorem{remark}{\textbf{Remark}}
\newtheorem{assumption}{\textbf{Assumption}}
\newtheorem{corollary}{\textbf{Corollary}}
\newtheorem{conjecture}{\textbf{Conjecture}}
\newtheorem{definition}{\textbf{Definition}}
\newtheorem{problem}{\textbf{Problem}}
%\newtheorem{proposition}{Proposition}
\newtheorem*{proof}{\textbf{Proof}}

\title{\LARGE \bf Secure State Estimation against Sparse Integrity Attack for System with Non-derogatory Dynamics}


\author{Zishuo Li$^*$ and Yilin Mo% <-this % stops a space
%\thanks{*This work was supported by }% <-this % stops a space
\thanks{Zishuo Li and Yilin Mo are with the Department of Automation and BNRist, Tsinghua University, Beijing, China. Email:\{\texttt{lizs19@mails.tsinghua.edu.cn, ylmo@mail.tsinghua.edu.cn}\}. This work is supported by the National Key Research and Development Program of China under Grant 2018AAA0101601.
}
\thanks{Corresponding author.}}
\date{}

\begin{document}



\maketitle
%\thispagestyle{empty}
%\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
We consider the problem of estimating the state of a time-invariant linear Gaussian system in the presence of integrity attacks. The attacker can compromise $p$ out of $m$ sensors, the set of which is fixed over time and unknown to the system operator, and manipulate the measurements arbitrarily. Under the assumption that all the unstable eigenvalues of system matrix $A$ have geometric multiplicity 1 (unstable part of $A$ is non-derogatory), we propose a secure estimation scheme that is resilient to integrity attack as long as the system is $2p$-sparse detectable, which is proved to be necessary for the existence of a secure estimation. In the absence of attack, the proposed estimation coincides with Kalman estimation with a certain probability that can be adjusted to balance between performance with and without attack. Furthermore, the detectability condition checking in the designing phase and the estimation computing in the online operating phase are both computationally efficient. A numerical example is provided to corroborate the results and illustrate the performance of the proposed estimator.


\end{abstract}
%We further prove that if the system is not $2p$-sparse detectable, there exists an attack strategy that no estimator has bounded error, which means our proposed estimator is secure whenever it is possible.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

As the confluence of sensors, platforms and networks increases, the already widespread applications of Cyber-Physical System (CPS) and Internet of Things (IoT) are expected to continue to emerge and expand \cite{2018DHS_report}.
They are playing an increasingly important role in critical infrastructures and everyday life, while the cyber-security risks and attack surfaces are also increasing \cite{cardenas2009challenges}.
However, CPS is vulnerable to a variety of cyber attacks since it usually relies on remote sensing devices, communication channels, and spatially distributed processors which are prone to failures when exposed to unintentional faults and malicious attacks.
Failure of CPS may cause sever damage to industrial infrastructures, economic order and environmental systems, e.g., the Stuxnet launched on Iranâ€™s nuclear facilities\cite{STUXNET}, power blackouts in Ukraine \cite{Ukraine_Blackout}, North America and Europe \cite{2003_blackout}, etc. The research community has recognized the importance of CPS security, especially the design of secure detection, estimation, and control strategy\cite{cardenas2009challenges}. 


%The efforts fall into two major categories based on how the physical plant is modeled: 1) steady-state estimation (no dynamics) and 2) linear time invariant dynamics. In both categories the malicious attacker is assumed to corrupt a subset of sensors by manipulating the measurements, and the system operator intend to recover the system state based on the partly corrupted measurements.


%For the design of state estimators, Teixeira et al.~\cite{teixeira2010cyber} analyzed the effects of possible deceptions attacks for state
%estimators and proposed some policies to design deception attacks for both linear and nonlinear state estimation. Qi et al.~\cite{qi2015event}
%considered the event-based attack strategy against remote state estimation. Recently, Mo and Sinopoli~\cite{mo2015} proposed an estimator that
%has minimum mean square error against the worst-case attacks. However, the problem of designing a secure state estimator for a dynamic system
%is much more challenging because the bias injected by an adversary can accumulate in the dynamic state estimation and give rise to a large or
%even unbounded estimation error~\cite{moscs10security, mo2016}.


%To overcome the problem of bias accumulation in the dynamic state estimation, 

Recently, substantial research efforts have been devoted to secure state estimation against various types of attacks, such as deception attacks \cite{mo2016tac},denial-of-service attacks \cite{yangguanghong2021tac} and false data injection attacks \cite{sandberg_TAC2014}. For false data injection attack, in order to identify the sparse malicious sensors and mitigate the impact of manipulated measurements, main research paths include error correction approach based on compressed sensing and begin estimation selection approach based on fault identification.
The error correction approach usually takes measurements in a finite time-window and adopts a sparsity-inducing optimization to handle the outliers. For example, minimizing the $\ell_0$ norm or its convex relaxation $\ell_1$ optimization for lower computational complexity\cite{FawziTAC2014}. Similarly, Shoukry and Tabuada \cite{ShoukryTAC2016} adopt a $2$-norm batch optimization approach for state estimation and a customized gradient descent algorithm to solve it efficiently.
However, in these works, the sensory data out of the time window are discarded, which may cause performance degradation and estimation delay.

Another solution is the switch estimator\cite{HespanhaACC2015}\cite{Shoukry2017}\cite{yorie}\cite{yangguanghong2018tac}\cite{luTAC2019} where the system operator switch between multiple estimate candidates\cite{HespanhaACC2015}\cite{yorie} or sensory data sources\cite{Shoukry2017}\cite{yangguanghong2018tac}\cite{luTAC2019} based on the evaluation of their reliability by consistency checking or malicious detection algorithms. However, the combinatorial nature of candidate estimates or sensor combinations poses challenges for storage or computation capability, and various solution are proposed. Shoukry et al.~\cite{Shoukry2017} aim at reducing searching complexity by Satisfiability Modulo Theory, and \cite{luTAC2019} reduces the number of candidates with the help of a set cover approach.
In view of the computational problems, Liu et al. \cite{liuxinghua-TAC2020} propose a secure estimation scheme based on decomposing Kalman filters into local estimators whose weighted sum recover the Kalman estimate with a certain probability in the absence of attack. The local estimates are fused securely by a quadratic programming problem with an $\ell_1$ term to handle the sparse outliers. However, in the designing phase, the sufficient condition for estimation resiliency is computationally hard to validate and stronger than $2p$-sparse observable, given that $2p$-sparse observable is the fundamental limit \cite{ShoukryTAC2016} for state reconstruction.
Similar to \cite{liuxinghua-TAC2020}, other results in the literature\cite{FawziTAC2014}\cite{sandberg_TAC2014} also impose more restrictive conditions than $2p$-sparse observable, whose validations are NP-hard problems.

In this paper, we intend to propose a estimation scheme that is secure to $p$ corrupted senors as long as the system is $2p$-sparse detectable under the assumption that stable part of $A$ is non-derogatory. This achieves the fundamental limit for dynamic state estimation since it has been proved that if the system is not $2p$-sparse detectable, there is no secure estimator \cite{yorie}. Moreover, by introducing non-derogatory assumption, the sparse detectablility index can be computed computational easily. For general system matrix $A$ with geometric multiplicity of unstable eigenvalues larger than 1, it has been proved that computing sparse observability is an NP-hard problem\cite{mao2021computational}, and there is no computational efficient solution unless P$=$NP. 
Therefore, our proposed scheme solves the computational complexity problem and acheives the fundamental limit at the same time.

%It has been proved   Moreover, for secure dynamic estimation the fundamental limit is proved to be $2p$-sparse detectable.
%
%In this paper, we intend to propose a 
%
% provides  these algorithms generally provides  to guarantee that there is an estimate that does not take measurements from corrupted sensors, the number of alternative estimates is combinatorial. Maintaining these estimates may incur heavy computation and storage burden of the devices and increase the complexity of selecting reliable estimates.
%
%Besides the aforementioned paths, Shoukry et al.~\cite{Shoukry2017} propose an algorithm by searching for reliable sensors using consistency check, and the searching complexity is reduced based on Satisfiability Modulo Theory.
%In addition to searching for reliable sensors, Guo et al. \cite{guoTSP2019} aim at locating compromised sensors by a Gaussian-mixture-model-based detection mechanism. The estimator fuses the measurements based on the belief given by the detection algorithm. 
%Liu et al. \cite{liuxinghua-TAC2020} design local estimators whose weighted sum coincides with the Kalman estimate with a certain probability in the absence of attack. The local estimates are fused securely by a quadratic programming problem with an $\ell_1$ term to handle the sparse outliers. 
%
%Even though various efficient secure estimation schemes have been provided by researchers, there are two aspects that can be improved.
%
%1) \textit{The computational complexity of secure estimator design can be significantly reduced.}
%For secure state recovery problem in the presence of $p$ malicious sensors, it is required that the system needs to be $2p$-sparse observable\cite{ShoukryTAC2016}, and calculating the sparse observability index for general systems is proved to be NP-hard\cite{yanwen_CDC19}. Besides sparse observability, other results \cite{FawziTAC2014}\cite{liuxinghua-TAC2020}\cite{sandberg_TAC2014} impose stronger conditions for system resiliency, whose validations are also NP problems.
%However, it has been observed by Mao et al. \cite{yanwen_CDC19} that when the eigenvalues of the system matrix $A$ have unitary multiplicity, the sparse observability index can be computed within polynomial time. 
%Leveraging upon this assumption, we prove that our proposed estimator is secure if the detectability index is no smaller than $2p$, which can be verified easily.
%
%2) \textit{The observability requirement for secure dynamic estimation can be relaxed.} For state reconstruction problem, it has been proved that $2p$-sparse observable is necessary for secure estimation\cite{ShoukryTAC2016}. However, for dynamic state estimation problem where dynamic is known to the system operator, observability for stable states is not required\cite{yorie}, since estimation error of stable states is trivially bounded (e.g., estimate stable states as 0). We propose an estimation scheme that is secure as long as the system is $2p$-sparse detectable, which is weaker than $2p$-sparse observable. Moreover, we also prove that this is necessary for a dynamic estimation to be secure. 

In view of the aforementioned problems, we propose a secure dynamic estimation scheme for linear Gaussian system, and it has the following merits:
%prove that the computation complexity of secure dynamic estimation problem with noise is 
%In this paper, we prove that the computation complexity can be reduced significantly under the assumption that all the eigenvalues of system matrix $A$ have geometric multiplicity 1.
%The secure state estimation design is improved upon the previous work \cite{liuxinghua-TAC2020} and has the following merits:
\begin{itemize}[left=0pt]
	\item In the presence of $p$ compromised sensors, the proposed estimation is secure if the system is $2p$-sparse detectable, which achieves the fundamental limit of secure state estimation.
	\item In the absence of attack, the proposed estimation coincides with Kalman estimation with certain probability, which can be adjusted to balance the performance with and without attack.
	\item During the designing phase, the sparse detectability index can be computed with low complexity. Moreover, during the algorithm operating phase, the proposed estimation is formulated as the solution of a convex optimization problem based on LASSO \cite{LASSOTibshirani}, which can be computed efficiently.
\end{itemize}


%researchers designed local estimates which can recovery 

%Mo et al. \cite{garone_cdc16}\cite{liuxinghua-IFAC} design a resilient estimator by decomposing the Kalman filter into linear combination of local estimates and securely fusing local information using a quadratic programming problem with an $\ell_1$ term, which can be solved efficiently within polynomial time. %with $\ell_1$ term that is robust to outliers. % optimization problem inspired by LASSO \cite{LASSOTibshirani}.
%By the design of local estimates, all the history information is maintained by the local estimators, in contrast to the moving horizon approach \cite{FawziTAC2014}\cite{ShoukryTAC2016} where sensory data before the time window are discarded. %The fused estimation coincides with optimal Kalman estimation for certain probability in the absence of attack. 


%Besides the estimator design, the fundamental limit of the secure estimation problem is provided by Shoukry et al. \cite{ShoukryTAC2016} in the form of $s$-sparse observability, i.e., in order to recover the original state in the presence of $p$ corrupted sensors, the system needs to be $2p$-sparse observable.
%However, checking sparse observability is NP-hard \cite{yanwen_CDC19} and thus introduce computationally intractable problems at the designing phase of a secure dynamic estimatior.
%Similarly, in \cite{sandberg_TAC2014} the vulnerability of the power network measurement system to false data attack is quantified by ``security index'', whose computation is also proved to be NP-hard. Similar condition is also seen in the state reconstruction problem (Proposition 6 in \cite{FawziTAC2014}) and dynamic estimation problem (Theorem 4 in \cite{liuxinghua-IFAC}), which renders evaluating system resiliency against corrupted sensors computationally hard.
%In this paper, we intend to reduce the computation complexity of the secure state estimation problem to polynomial time when it is possible.
%For the algorithm designing phase, we prove that when all the eigenvalues of system matrix $A$ have geometric multiplicity 1, the sparse observability can be calculated within polynomial time.
%If the system is $s$-sparse observable, we propose a secure dynamic estimation scheme in the presence of $\left \lfloor s/2 \right \rfloor$ compromised sensors. Our proposed secure estimation coincides with Kalman estimation for certain probability in the absence of attack. 
%For the algorithm running phase, the secure estimation can be obtained within polynomial computation time.% since we introduce an 


 
%In this paper, we intend to reveal the observability/detectability condition for the existence of a secure dynamic estimator against integrity attack, i.e., when does the secure dynamic estimator exist and when does not, and provide an algorithm to check the condition efficiently.
%
%The observability condition required for the state reconstruction problem without noise has been studied by Tabuada et al. \cite{FawziTAC2014,HespanhaACC2015,ShoukryTAC2016,yanwen_CDC19}. It has been proved that the exact initial state can be recovered in the presence of $p$ compromised sensors if the system is observable after removing $2p$ sensors, i.e., $2p$-sparse observable \cite{ShoukryTAC2016}. 
%%In view of this property, the \textit{sparse observability}\cite{ShoukryTAC2016} or observability under attack\cite{HespanhaACC2015} is introduced to characterize the system observability in the presence of malicious sensors.
%However, checking the sparse observability is computationally hard \cite{FawziTAC2014}\cite{yanwen_CDC19} due to its combinatorial nature. 
%Moreover, these established results on state reconstruction without noise cannot be trivially extended to the secure dynamic estimation problem where noise and malicious injected data both disturb the measurements since the sensory data inconsistency could be attributed to noise. 

%Therefore, our work is contributing since we propose a secure estimation scheme for LTI system with Gaussian noise that is optimal without attack and resilient under $p$ corrupted sensors for all $2p$-sparse detectable systems under an assumption on system matrix $A$. Moreover, an algorithm is provided for checking sparse observability/detectability in polynomial time.

% we propose a secure dynamic state estimator which is resilient to $p$ malicious sensors as long as the system is $2p$-sparse observable under an assumption on system matrix $A$. 
%In the absence of attack, the proposed estimation is equivalent to the optimal Kalman estimation for certain probability.
%We also provide an extension that the condition could be further relaxed to $2p$-sparse detectable, which is necessary for the existence of an resilient estimator. 

% we answer the following questions in this paper:
%\begin{itemize}[left=0pt]
%	\item When does the system has a resilient estimator and when does not?
%	\item How to validate the resiliency condition with low computational effort?
%	\item What is the design of the resilient estimator when the condition holds?
%\end{itemize}

\textit{Organization:} We introduce the problem formulation and preliminary results in Section \ref{sec:problem}. The main results are provided in Section \ref{sec:main_result} and collaborated by numerical simulation in Section \ref{sec:sim}. Section \ref{sec:conclusion} finally concludes the paper.

\textit{Notations:}
Cardinality of a set $\Sc$ is denoted as $n_s$. $A{'}$ represents conjugate transpose of matrix $A$.
%The determinant of a matrix is represented by $\det(\cdot)$. 
Diagonal matrix with diagonal elements $A_1,\cdots,A_k$ is denoted as $\text{diag}(A_1,\cdots,A_k)$.
Denote the span of row vectors of matrix $A$ as $\rs(A)$.
All-one vector with size $m\times 1$ is denoted as $\mathbf{1}_{m}$. $I_n$ is the identity matrix with size $n\times n$. 
$\Cb^{m\times n}$ ($\Rb^{m\times n}$) represents the set of complex (real) matrices with $m$ rows and $n$ columns.
The $i$-th entry of a vector $x$ is represented by $x_i$ or $[x]_i$. $\|\cdot\|_q$ represents the vector $q$-norm or (induced) matrix $q$-norm which is clear according to the context.
%Suppose $\Sc$ is an index set, define $A^\Sc$ as the matrix composed of the columns of matrix $A$ with column indices in $\Sc$. If $\Sc$ is a singleton e.g., $\Sc=\{i\}$, it is denoted as $A^{(i)}$.


\section{Problem Formulation and Preliminary Results}\label{sec:problem}	
\subsection{Secure dynamic state estimation}
In this paper, we consider the linear time-invariant system with Gaussian noise:
\begin{align}
x(k+1)&=A x(k)+Bu(k)+w(k) , \label{eq:system} \\
y(k)&=C x(k)+v(k)+a(k) ,\label{eq:y_i_def}
\end{align}
where $x(k) \in \mathbb{R}^{n}$ is the system state, $w(k) \sim {N}(0, Q)$ and $v(k) \sim {N}(0, R)$ are i.i.d. Gaussian process noise and measurement noise with zero mean and covariance matrix $Q$ and $R$.  
Vector $u(k)\in \mathbb{R}^{d}$ is the external input.  
The vector $y(k)\in \mathbb{R}^{m}$ is the collection of measurement from all $m$ sensors, and $i$-th entry $y_i(k)$ is the measurement from sensor $i$.
The vector $a(k)$ denotes the bias injected by an adversary and $a_i(k)$ is the attack on sensor $i$. Define $$z(k)=C x(k)+v(k)$$ as the true measurements without the attack.
The initial state $x(0) \sim {N}(0, \Sigma)$ is assumed to be zero mean Gaussian and is independent from the process noise $\{w(k)\}$.


%Assume that $m$ sensors are measuring the system and the measurement from the $i$-th sensor is:
%\begin{equation}\label{eq:y_i_def}
%	y_{i}(k)=C_{i} x(k)+v_{i}(k)+a_{i}(k)=z_{i}(k)+a_{i}(k), 
%\end{equation}
%where $y_{i}(k) \in \mathbb{R}, C_{i} \in \mathbb{R}^{1 \times n}$ and $v_{i}(k) \in \mathbb{R}$ is Gaussian
%measurement noise. The scalar $a_{i}(k)$ denotes the bias injected by an adversary, and $z_{i}(k)=C_{i} x(k)+v_{i}(k)$ can be regarded as the true measurement without the bias.
%Equation (\ref{eq:y_i_def}) can be written in a compact form :
%\begin{equation}
%	y(k)=C x(k)+v(k)+a(k)=z(k)+a(k)
%\end{equation}
%with
%\begin{align}
%	&y(k) \triangleq\begin{bmatrix}
%		y_{1}(k) \\
%		\vdots \\
%		y_{m}(k)
%	\end{bmatrix}  ,
%	z(k) \triangleq\begin{bmatrix}
%		z_{1}(k) \\
%		\vdots \\
%		z_{m}(k)
%	\end{bmatrix}  ,
%	C \triangleq\begin{bmatrix}
%		C_{1} \\
%		\vdots \\
%		C_{m}
%	\end{bmatrix} , \\
%	&a(k)  \triangleq\begin{bmatrix}
%		a_{1}(k) \\
%		\vdots \\
%		a_{m}(k)
%	\end{bmatrix}  ,
%	v(k) \triangleq\begin{bmatrix}
%		v_{1}(k) \\
%		\vdots \\
%		v_{m}(k)
%	\end{bmatrix}.
%\end{align}
%We assume that $v(k) \sim {N}(0, R)$ with $R\succ 0$ is i.i.d and independent of the noise process $\{w(k)\}$ and the initial condition $x(0)$.
The secure dynamic estimation problem aims at recovering system state $x(k)$ at every time $k$ based on all history observations and inputs $\{y(t),u(t) | 0\leq t\leq k\}$, where $y(k)$ has been partly manipulated by the malicious attacker.
It is conventional in the literature \cite{FawziTAC2014}\cite{Shoukry2017} that the attacker can only compromise a fixed subset of sensors with known maximum cardinality. 
Denote the index set of all sensors as $\Oc \triangleq\{1,2, \ldots, m\}$. 
For any index set $\Ic \subseteq \Oc,$ define the complement set to be $\Ic^{c} \triangleq$ $\Oc \backslash \Ic$. 
Define the support of vector $a\in\Rb^{n}$ as $\supp(a)\triangleq \left\{i| 1\leq i\leq n , a_i\neq0 \right\}$ where $a_i$ is the $i$-th entry of vector $a$.
We have the following assumptions on the malicious adversary. 
We introduce the following assumption on the attack.
%In our attack model, we assume that the attacker can only compromise at most $p$ sensors but can arbitrarily choose the injected data $a_{i}(k)$. Formally, a $(p, m)$-sparse attack can be defined as follows. 

\begin{definition}[Sparse Attack]\label{def:attack}
	The attack called a $(p, m)$-sparse attack if the vector sequence $a(k)$ satisfy that,
	there exists a time invariant index set $\Ic\subseteq \Oc $ with $|\Ic| = p$ such that $\bigcup_{k=1}^{\infty} \supp\left\{a(k)\right\} = \Ic$.
\end{definition}

Closely related to the sparse attack, we introduce the notion of sparse observability (detectability) that characterizes the system observability (detectability) in the presence of attack.

\begin{definition}[Sparse observable / detectable]\label{df:sparse_obs}
	The sparse observability (detectability) index of system \eqref{eq:system}-\eqref{eq:y_i_def} is the largest integer $s$ such that system\footnote{The matrix $C_{\Oc\setminus\Ic}$ represents the matrix composed of rows of $C$ with row index in $\Oc\setminus\Ic$.} $(A,C_{\Oc\setminus\Ic})$ is observable (detectable) for any set of sensors $\Ic\subset\Oc$ with cardinality $|\Ic| = s$. When the sparse observability (detectability) index is $s$, we say that the system with pair $(A,C)$ is $s$-sparse observable (detectable).
\end{definition}
%Define the collection of all possible index sets of $p$ malicious sensors as follows:
%$$
%\Cc \triangleq\{\Ic: \Ic \subset \Oc,|\Ic|=p\}.
%$$
%The set of all possible $(p, m)$-sparse attacks is denoted as follows:
%$$
%\mathcal{A} \triangleq \bigcup_{\Ic \in \Cc}\left\{a:\left\|a_{i}\right\|=0, i \in \Ic^{c}\right\}
%$$
Define $y(k_1:k_2)$ as the sequence $\{y(k_1),y(k_1+1),\cdots,y(k_2)\}$. Similar notation is also applied on $z(k),u(k)$.	
An estimator is an infinite sequence of mappings $g=\{g_k\}_{k=1}^{\ift}$ where $g_k$ is a mapping from all the history outputs and inputs to an state estimation at time $k$:
$$g_k\left(y(0:k),u(0:k)\right)=\hat{x}(k).$$
It is written as $g_k(y,u)=\hat{x}(k)$ for notation simplicity.
For linear Gaussian noise system, the estimation is secure if the estimation error covariance is bounded by a constant term irrelevant to the attack. 
%The main task of this paper is to investigate the sufficient and necessary conditions for the existence of an estimator to be resilient to $(p, m)$-sparse attacks and design the resilient estimator whenever the condition holds.
%To this end, we first formally define the resilience of an estimator.

\begin{definition}[Secure estimator]\label{def:resi}
	
	Define the estimation difference introduced by attack as
	\begin{align*}
	q_k\triangleq \left\|g_k\left(z,u\right)-g_k\left(y,u\right) \right\|_2 
	=\left\|g_k\left(z,u\right)-g_k\left(z+a,u\right) \right\|_2 .
	\end{align*}
	The estimator is said to be secure against $(p, m)$-sparse attack if the following holds:
	%there exists a constant $q$ such that  
	$$\sup_{k\in\Zb^+} \Eb \left[q_k^2\right] < \ift ,$$
	where $\Eb$ is the expectation with respect to the probability measure defined by the Gaussian noise $\{w(k)\}$ and $\{v(k)\}$.
\end{definition}
If all sensors are benign, i.e., $a(k)=\mathbf{0}$ for all $k$, the optimal state estimator is the classical Kalman filter:
\begin{align*}
	\hat{x}(k)&=\hat{x}(k | k-1)+K(k)\left[y(k)-C \hat{x}(k  | k-1)\right] ,\\
	P(k)&=P(k  | k-1)-K(k) C P(k  | k-1),
\end{align*}
where
\begin{align*}
	&\hat{x}(k  | k-1)=A \hat{x}(k-1)+Bu(k), P(k  | k-1)=A P(k-1) A{'}+Q ,\\	
	&K(k)=P(k  | k-1) C{'}\left(C P(k  | k-1) C{'}+R\right)^{-1},
\end{align*}
with initial condition $\hat{x}(0  |-1)=0,\ P(0  |-1)=\Sigma $.
It is well-known that for observable system, the estimation error covariance matrices $P(k)$ and the gain $K(k)$ will converge to
\begin{align*}
	P \triangleq \lim _{k \rightarrow \infty} P(k),\ P_{+}=A P A{'}+Q ,\ K \triangleq P_{+} C{'}\left(C P_{+} C{'}+R\right)^{-1}.
\end{align*}
Since typically the control system will be running for an extended period of time, we focus on the case where the Kalman filter is in steady state, and thus the Kalman filter reduces to the following fixed-gain linear estimator:
\begin{equation}\label{eq:fix_gain_kalman}
	\hat{x}(k+1)=(I-K C) \left(A \hat{x}(k)+Bu(k)\right)+K y(k+1) .
\end{equation}
Before introducing our work, we first recall some results in the previous work that decomposes the fix gain Kalman filter to local estimates and recovers it securely by an optimization problem. % which is the basis of this paper.

%The main task of this paper is to propose a secure sensor information fusion scheme that is optimal both in the absence and presence of attack.
%In the absence of attack, the estimation is the same as Kalman Filter and thus optimal in the sense of minimum mean square error. In the presence of attack, the estimation is resilient according to Definition \ref{def:resi} as long as for every unstable state, there are more honest sensors than corrupted sensors observing it. It is optimal in the sense that if this condition is violated, there exists an attack that can drive the estimation $g(z+a)$ to be arbitrarily large~\cite{yorie}.


\subsection{Preliminary Results}\label{sec:preli}
We introduce some preliminaries in this subsection which are fundamental to main results in this paper.
We introduce the following assumption:
\begin{assumption}\label{as:distinct_eigvalue}
	The matrix $A$ is invertible; $A-K C A$ has $n$ distinct eigenvalues. Moreover, $A-K C A$ and $A$ do not share any eigenvalue.
\end{assumption}
\begin{remark}
	Since the invertibility of A implies that $(A, CA)$
is also observable, we can freely assign the poles of $A-KCA$ by choosing a proper gain $K$. Hence, $A-KCA$ can satisfy the condition in Assumption \ref{as:distinct_eigvalue} with a small estimation performance loss.
\end{remark}
Since $A-K C A$ has distinct eigenvalues, it can be diagonalized as:
\begin{equation}\label{eq:VLambda}
	A-K C A=V \Pi V^{-1}.
\end{equation}
Define the eigenvalues of $A-KCA$ as $\pi_{1},\cdots,\pi_{n}$.
Consider local estimation $\zeta_{i}(k)$ which is the system response of sensor $i$. The local estimator satisfies the following dynamic:
\begin{equation}\label{eq:def_zeta}
	\zeta_{i}(k+1)=\Pi \zeta_{i}(k)+\mathbf{1}_{n} y_{i}(k+1)+\left(G_i-\mathbf{1}_n C_i\right)Bu(k) ,
\end{equation}
%where the column vector $\mathbf{1}_{m}$ represents the all-one vector with $m$ entries.
%Define Fi as
%$$
%F_{i}=V \operatorname{diag}\left(V^{-1} K_{i}\right)
%$$
%where V is defined in (???) and diag(Vâˆ’1Ki) is an nÃ—n diagonal matrix with the j th diagonal entry equals to the j th entry of the vector Vâˆ’1Ki. 
%
%We have the following proposition from \cite{liuxinghua-IFAC}.
%\begin{proposition}
%	The Kalman filter can be decomposed as linear composition of Î¶i(k):
%	\begin{equation}\label{eq:kalman_decomp}
%		\hat{x}(k)=\sum_{i=1}^{m} F_{i} \zeta_{i}(k).
%	\end{equation}
%\end{proposition}
%
%Moreover, the relationship between Î¶i(k) and x(k) is shown in the following proposition (\cite{liuxinghua-IFAC} Theorem 1).
where $C_i$ is $i$-th row of matrix $C$, and $G_i$ is defined as
\begin{equation}\label{eq:def_Gi}
	G_{i} \triangleq\left[\begin{array}{c}
		C_{i} A\left(A-\pi_{1} I\right)^{-1} \\
		\vdots \\
		C_{i} A\left(A-\pi_{n} I\right)^{-1}
	\end{array}\right].
\end{equation}
The following lemma shows the relationship between $\zeta_i(k)$ and $G_ix(k)$.
%the difference between them converge to a stationary Gaussian process in the absence of attack.
\begin{lemma}\label{lm:epsilon}
	$\zeta_i(k)$ is stable estimation of $G_ix(k)$. Define their difference as $\epsilon_i(k)\triangleq\zeta_{i}(k)-G_ix(k)$, then $\epsilon_i(k)$ satisfy the following dynamics:
	\begin{align}
		\epsilon_{i}(k+1)= \Pi \epsilon_{i}(k)-\left(G_{i}-\mathbf{1}_{n} C_{i}\right) w(k) 
		+\mathbf{1}_{n} v_{i}(k+1)&+\mathbf{1}_{n} a_{i}(k+1) . \label{eq:epsilon}
	\end{align}
\end{lemma}
\begin{proof}
	According to the definition of $\zeta_{i}(k+1)$, one obatins
	\begin{align*}
	\epsilon_{i}(k+1)=&\Pi\zeta_{i}(k)+\mathbf{1}_n\left[C_i\left(Ax(k)+Bu(k)+w(k)\right)+v_i(k+1)+a_i(k+1)\right]\\
	&-\left(G_{i}-\mathbf{1}_{n} C_{i}\right)Bu(k)-G_i\left(Ax(k)+Bu(k)+w(k)\right)\\
	=&\Pi\zeta_{i}(k)-\left(G_iA-\mathbf{1}_nC_iA\right)x(k)- \left(G_{i}-\mathbf{1}_{n} C_{i}\right) w(k) 
	+\mathbf{1}_{n}\left( v_{i}(k+1)+ a_{i}(k+1) \right)
	\end{align*}
	Since it has been proved in \cite{liuxinghua-TAC2020} Corollary 1 that $G_iA-\mathbf{1}_nC_iA=\Pi G_i$, one can verify that equation \eqref{eq:epsilon} holds. $\square$
\end{proof}
Define $\tilde{Q} \in \Cb^{m n \times m n}$ as the covariance of noise term $\left(G_{i}-\mathbf{1}_{n} C_{i}\right) w(k) -\mathbf{1}_{n} v_{i}(k+1)$ for all $i$, i.e.,
\begin{align}
	\tilde{Q} \triangleq
	\begin{bmatrix}
		G_1-\mathbf{1}_{n} C_1 \\
		\vdots \\
		G_m-\mathbf{1}_{n} C_m
	\end{bmatrix}
	Q\begin{bmatrix}
		G_1-\mathbf{1}_{n} C_1 \\
		\vdots \\
		G_m-\mathbf{1}_{n} C_m
	\end{bmatrix}^{'}
	+ R\otimes \mathbf{1}_{n\times n},
\end{align}
where $\otimes$ is the Kronecker product.
Define $\tilde{\Pi}\in \Cb^{m n \times m n}$ as
$$
\tilde{\Pi} \triangleq\left[\begin{array}{ccc}
	\Pi & & \\
	& \ddots & \\
	& & \Pi
\end{array}\right].
$$
%\textbf{\footnote{$\epsilon(k)$ and $\epsilon_i(k)$ is defined in Lemma \ref{lm:epsilon}}}
The stable covariance of $\epsilon(k)\triangleq\left[\epsilon_1(k){'},\cdots,\epsilon_m(k){'}\right]{'}$ is the solution $\tilde{W}$ of the following Lyapunov equation:
$$
\tilde{W}=\tilde{\Pi} \tilde{W} \tilde{\Pi}{'}+\tilde{Q}.
$$ 
The matrix $\tilde{W}$ is well-defined since $\Pi$ is strictly stable. As a result, the secure estimation can be recovered by the solution of the following optimization problem where $\zeta(k)\triangleq\left[\zeta_1(k){'},\cdots,\zeta_m(k){'}\right]{'} $ and $G\triangleq\left[G{'}_1,\cdots,G{'}_m\right]{'} $.
\begin{subequations}\label{pb:old_lasso}
	\begin{align}
		\underset{\check{x}(k), \mu(k), \nu(k)}{\operatorname{minimize}}&\quad \frac{1}{2} \mu(k){'} \tilde{W}^{-1} \mu(k) + \gamma \|\nu(k)\|_1 \label{min:old_lasso} \\
		\text{subject to }&\quad
		\zeta(k)=
		G \check{x}(k)+\mu(k)+\nu(k). \label{eq:old_lasso}
	\end{align}
\end{subequations}
The parameter $\gamma$ is a non-negative constant chosen by the system operator. The following theorem from \cite{liuxinghua-TAC2020} proves that the solution $\check{x}(k)$ to problem (\ref{pb:old_lasso}) is a secure estimation under specific condition.
\begin{theorem}[\hspace{-0.01pt}\cite{liuxinghua-TAC2020}]\label{th:TAC}
	In the presence of $(p, m)$-sparse attack, the state estimation $\check{x}(k)$ is secure if the following inequality holds for all $x \neq \mathbf{0}$, $x\in\Rb^n$:
\begin{equation}\label{eq:cond}
	\sum_{i \in \mathcal{I}}\left\|G_{i} x\right\|_{1}<\sum_{i \in \mathcal{I}^{c}}\left\|G_{i} x\right\|_{1}, \quad \forall\ \Ic\subset \Oc, |\mathcal{I}|\leq p .
\end{equation}
\end{theorem}
Even though Theorem \ref{th:TAC} establishes the sufficient condition of the estimation to be secure, this condition can be improved in the following two aspects as illustrated in the introduction section.
\begin{enumerate}[left=0pt]
	\item Validating condition \eqref{eq:cond} is NP-hard. The computational complexity can be significantly reduced by relating $G_i$ to observable space corresponding to sensor $i$.
	\item Condition \eqref{eq:cond} does not achieve the fundamental limit. It is more restrictive that $2p$-sparse observability and has a gap from $2p$-sparse detectablity.
\end{enumerate}

In the following section, we proposed a secure estimation scheme that improves the aforementioned two points.
Under assumption on unstable eigenvalues of $A$, the sufficient condition of the estimation to be secure is proved to be $2p$-sparse detectable, which is easily validated and also necessary.

% This means the sufficient condition ($2p$-sparse detectable) is also necessary. Thus, the aforementioned two points are improved and we propose a secure estimation scheme as long as it is possible to recover estimates securely. 

%paper, we make an observation that the structure of $G_i$ is essentially the same with the observability matrix $[C_i{'},(C_iA){'},\cdots,(C_i A^{n-1}){'}]{'}$, which enable us to design a optimization problem based on \eqref{pb:old_lasso} whose solution is a resilient estimation as long as the system is $2p$-sparse observable. 
%Even though the problem of checking sparse observability index is NP-complete (see \cite{yanwen_CDC19} Theorem 3), we prove in this paper that for some specific categories of system, it can be done in polynomial time.
%To summarize, in the following sections, we propose a secure dynamic state estimation scheme that has the following property:
%\begin{itemize}[left=0pt]
%	\item In the algorithm design phase, the sparse observability index $s$ can be calculated within polynomial time with an assumption on $A$.
%	\item In the algorithm running phase, the estimation can be obtained within polynomial computation time. 
%	\begin{itemize}
%		\item The estimation is resilient in the presence of at most $\left \lfloor s/2 \right \rfloor$ compromised sensors.
%		\item In the absence of attack, the estimation coincides with fixed gain Kalman filter defined in (\ref{eq:fix_gain_kalman}) for certain probability.
%	\end{itemize}
%\end{itemize}
%In the following section, the proposed estimator is introduced and main results are established.

\section{Secure Estimation with Sparse Detectability}\label{sec:main_result}
In this section, under the assumption that all the unstable eigenvalues of $A$ have geometric multiplicity $1$, we design a state estimator that is secure in the presence of $(p,m)$-sparse attack as long as the system $(A,C)$ is $2p$-sparse detectable. Moreover, we prove that if the system is not $2p$-sparse detectable, there exists an attack strategy under which no estimator can be secure.
%In this section, under the assumption on $A$, we first prove the relationship between span of row vectors of $G_i$ defined in \eqref{eq:def_Gi} and observable space of $(A,C_i)$. Leveraging the structure of $G_i$ and careful design of the optimization problem, we prove that the estimation is secure to $p$ compromised sensors if the system is $2p$-sparse detectable.
We first introduce the following assumption on unstable eigenvalues of $A$.

\begin{assumption}\label{as:geo_unstable}
	All the unstable eigenvalues of $A$ have geometric multiplicity $1$. 
\end{assumption}
Since we can perform invertible linear transformation $T$ on state $x$ and study the following system instead:
\begin{align*}
\bar{x}(k)&= \bar{A} \bar{x}(k) + TB\bar{x}(k)+Tw(k),  \\
y(k)&=CT^{-1}\bar{x}(k)+v(k)+a(k) ,
\end{align*}
where $\bar{A}\triangleq TAT^{-1}$ is similar to $A$ and $\bar{x}=Tx$, we can assume that $A$ is in the following Jordan form without loss of generality:
	\begin{align*}
	&A=
	\begin{pmatrix}
	\begin{array}{cc}
	A_1 & \mathbf{0} \\
	\mathbf{0} & A_2			
	\end{array}
	\end{pmatrix}, \
	%	A_\Uc=\begin{pmatrix}
	%	J_{1} & \mathbf{0} & \cdots & \mathbf{0} \\
	%	\mathbf{0} & J_{2} & \cdots & \mathbf{0} \\
	%	\vdots & \vdots & \ddots & \vdots \\
	%	\mathbf{0} & \mathbf{0} & \cdots & J_{l} 
	%	\end{pmatrix},	\\
	%	&
	%	\text{where } J_k=
	%	\begin{pmatrix}
	%	\lambda_{k} & 1 & 0 & \cdots & {0} \\
	%	{0} & \lambda_{k} & 1 &  \cdots & {0} \\
	%	\vdots & \vdots &  \vdots & \ddots & \vdots \\
	%	{0} & {0} & {0} & \cdots & \lambda_{k} 
	%	\end{pmatrix} ,
	%\in \Cb^{n_k \times n_k} , \sum_{k=1}^{l}n_k =|\Uc| .
	\end{align*}
	where block $A_1$ is composed of the Jordan blocks with unstable eigenvalues and $A_2$ is composed of the Jordan blocks with stable eigenvalues. 



Denote the number of unstable eigenvalues of $A$ (counted with repetition) as $n_u$ and number of stable eigenvalues as $n_s$.
In order to analyze stable and unstable states separately with simple notation, we denote the index set of unstable entries\footnote{Unstable entries of state $x$ are the entries $x_i$ corresponding to eigenvalue $|\lambda_i| \geq1$.} of state as $\Uc\triangleq\{1,2,\cdots,n_u\}$ and index set of stable entries as $\Sc\triangleq\{n_u+1,\cdots,n\}$. 
Furthermore, a matrix $X$ can be divided vertically to two sub-matrices 
\begin{equation*}
X=\left[\begin{array}{c} X^\Uc \ | \ \ X^\Sc\end{array}\right] ,
\end{equation*}
where $X^\Uc$ is the matrix composed of first $n_u$ columns of matrix $X$ and $X^\Sc$ is composed of last $n_s$ columns of $X$. 
%For example, according to Assumption \ref{as:geo_unstable}, $A^\Uc=\begin{bmatrix} A_1\\ \mathbf{0} \end{bmatrix}, A^\Sc=\begin{bmatrix} \mathbf{0} \\ A_2 \end{bmatrix}$.
Define the observable matrix of system $(A,C_i)$ as 
\begin{equation}\label{eq:def_O}
O_{i} \triangleq\left[\begin{array}{c|c|c|c}
C_{i}{'} &
\left(C_{i} A\right){'} &
\cdots &
\left(C_{i} A^{n-1}\right){'}
\end{array}\right]{'}.
\end{equation}
Therefore, $\rs(O^\Uc_{i})$ is the observable subspace of sensor $i$ corresponding to unstable states.

\subsection{Canonical form of $G_i$}\label{subsec:transform}
We prove in this subsection that the row span of $G^\Uc_i$ coincides with $\rs(O^\Uc_{i})$, which implies that the matrix $G^\Uc_i$ has a canonical form under row operations. 
Before continuing on, we need the following notation of state-sensor observability. 
%Define $\Sc\triangleq \{1,2,\cdots,n\}$ as the index set of all states and $\Sc_i\subseteq\Sc$ as the index set of states that sensor $i$ can observe, i.e.,
%\begin{equation}
%	\Sc_i\triangleq \{j\in\Sc\ |\ O_i{'} e_j\neq \mathbf{0} \},
%\end{equation}
Define $\Ec_j$ as the index set of sensors that can observe state $j$, i.e.
\begin{equation}\label{eq:def_Ec}
\Ec_j\triangleq \{i\in\Oc\ |\ O_i{'} e_j\neq \mathbf{0} \},
\end{equation}
where $\Oc\triangleq \{1,2,\cdots,m\}$ is the index set of all sensors and $e_j$ is the $n$-dimensional canonical basis vector with 1 on the $j$-th entry and 0 on the other entries.
We have the following theorem characterizing the structure of $G_i$. 
\begin{theorem}\label{th:span}
	Assume system matrix $A$ satisfies Assumption \ref{as:geo_unstable}, then the following equation holds:
	\begin{align}\label{eq:span}
	\rs(G_i^\Uc)=\rs(O_i^\Uc)=\rs(H_i^\Uc) ,
	\end{align}
	where $H^\Uc_i$ is the following $n\times n_u$ matrix
	\begin{equation*}
	H_i^\Uc\triangleq \begin{bmatrix}
	\Ib_{i\in\Ec_1} & & \\
	& \ddots&   \\
	& & \Ib_{i\in\Ec_{n_u}}\\
	\hline \\
	& \mathbf{0} &\\
	& &
	\end{bmatrix} ,
	\end{equation*}
	and $\mathbb{I}_\Es$ is the indicator function that takes the value 1 when $\Es$ is true and value 0 when $\Es$ is not.
	Therefore, there exists an invertible $n\times n$ matrix $P_i$ such that $P_iG_i=H_i$ and $H_i$ is in the following form:
	\begin{equation*}
	H_i=P_iG_i=\left[\begin{array}{c} H_i^\Uc \ | \ \ P_i G^\Sc_i\end{array}\right] .
	\end{equation*}
\end{theorem}

%Theorem \ref{th:span} directly follows Theorem 2 in \cite{} and is omitted because of space limit.
Proof of Theorem \ref{th:span} is provided in Appendix \ref{ap:span}.
After transformation $P_i$, matrix $G^\Uc_i$ is transformed into canonical form $H^\Uc_{i}$ whose rows are either canonical basis vectors or zero vectors. 
The non-zero entries of $H_i$ records the state observability of sensor $i$. Therefore, the sparse detectability index can be directly obtained from $H^\Uc_i$.
\begin{corollary}\label{co:sparse_obs}
	The sparse observability index of system $(A,C)$ is $\min_{j\in\{1,2,\cdots,n\}} \left|\Ec_{j}\right| - 1 $.
	The sparse detectability index of system $(A,C)$ is $\min_{j\in\Uc} \left|\Ec_{j}\right| - 1 $ if $\Uc\neq\varnothing$ and is $n$ if $\Uc=\varnothing$.
\end{corollary} 
\begin{remark}
	Since we focus on observable system, then for each $j\in\{1,2,\cdots,n\}$, $\Ec_j\neq\varnothing$. Thus, the observability index and detectability index are non-negative integers.
\end{remark}
\begin{proof}
	For arbitrary $\overline{s}$ that satisfy $\overline{s}\geq s+1$, there exists a state index $j^*$ and a sensor index set $\Ic^*$ with $|\Ic^*|=\overline{s}$ such that $\Ec_{j^*} \cap \left(\Oc\setminus\Ic^*\right)=\varnothing$.
	As a result, state $j^*$ can not be observed by any sensor in $\Oc\setminus \Ic^*$, i.e.,
	\begin{equation*}
		e_{j^*}\notin \rs(O_i),\ \forall i\in\Oc\setminus \Ic^*.
	\end{equation*}
	and thus system $(A,C_{\Oc\setminus\Ic^*})$ is not observable.
	For arbitrary $\underline{s}$ that satisfy $\underline{s}\leq s$, arbitrary $j$ and arbitrary $\Ic$ with $|\Ic|=\underline{s}$, one obtains $\Ec_{j^*} \cap \left(\Oc\setminus\Ic^*\right)\neq\varnothing$, which means for all $j$, there exists $i^*\in\Oc\setminus \Ic$ such that: $e_{j}\in \rs(O_{i^*})$. Therefore, system $(A,C_{\Oc\setminus\Ic})$ is observable. According to Definition \ref{df:sparse_obs}, the system is $s$-sparse observable. The detectability index is obtained in the same way by considering unstable subsystem when $\Uc\neq \varnothing$. When $A$ is stable, system is always detectable according to definition $\square$
\end{proof}

In conclusion, under Assumption \ref{as:geo_unstable}, the matrix $G^\Uc_i$ has a canonical form which is determined by state-sensor observability. Leveraging upon the canonical form $H^\Uc_i$, we will propose an estimation scheme that is secure in the presence of $(p,m)$-sparse attack as long as the system is $2p$-sparse detectable.

\subsection{Secure Estimation Design}
Recalling the transformation $P_i$ introduced in Theorem \ref{th:span}, define $\tilde{P} \triangleq \text{diag}\left(P_1,\cdots,P_m\right),\ \tilde{M}\triangleq\tilde{P}\tilde{W}\tilde{P}{'}$ and
\begin{align}\label{eq:def_YH}
{Y} (k)\triangleq
\begin{bmatrix}
P_1\zeta_{1}(k) \\
\vdots \\
P_m\zeta_{m}(k)
\end{bmatrix}\in\Cb^{mn\times 1}, \
H\triangleq\begin{bmatrix}
H_{1} \\
\vdots \\
H_{m}
\end{bmatrix}\in\Cb^{mn\times n} .	
\end{align}
Define the following matrix
\begin{align*}
&\Nc\triangleq
I_{m} \otimes 
\begin{bmatrix}
\mathbf{0}_{n_s\times n_u} & I_{n_s}
\end{bmatrix}
\in \Rb^{mn_s\times mn }.
\end{align*}
Consider the following least square problem.
\begin{subequations}\label{pb:least_square}
	\begin{align}
	\underset{{\tilde{x}_\ls}(k), \varphi(k)}{\text{minimize}}&\quad \frac{1}{2} 
	\begin{bmatrix}
	\varphi(k) \\
	\Nc H \tilde{x}_\ls(k)
	\end{bmatrix}^{'} \Wc
	\begin{bmatrix}
	\varphi(k) \\
	\Nc H \tilde{x}_\ls(k)
	\end{bmatrix}  \\
	\text {subject to}&\quad
	{Y} (k)= H \tilde{x}_\ls(k)+\varphi(k).  
	\end{align}
\end{subequations}
where 
\begin{align}\label{eq:def_W}
\Wc\triangleq \begin{bmatrix}
\tilde{M}^{-1}+ \Nc{'}\Nc & \Nc{'} \\
\Nc &  I
\end{bmatrix}.
\end{align}
Notice that $\Wc$ is positive definite since $\tilde{M}^{-1}\succ 0$.
Define\footnote{$\diag(V^{-1}K_i)$ is a $n\times n$ diagonal matrix whose diagonal with the $j$-th diagonal entry equals to $j$-th element of vector $V^{-1}K_i$.} 
$F_i\triangleq V\diag(V^{-1}K_i),\ F=\begin{bmatrix} F_1&\cdots & F_m \end{bmatrix}$,
where $V$ is defined in \eqref{eq:VLambda}.
Recall that $\epsilon(k)\triangleq\left[\epsilon_1(k){'},\cdots,\epsilon_m(k){'}\right]{'}$ and $\epsilon_i(k)=\zeta_i(k)-G_ix(k)$ from Lemma \ref{lm:epsilon} and fix gain Kalman estimation $\hat{x}(k)$ from \eqref{eq:fix_gain_kalman}.
\begin{lemma}\label{lm:least_square}
	In the absence of attack,  the solution to least square problem \eqref{pb:least_square} coincides with the Kalman estimation and satisfies the following:
	\begin{equation*}
	\tilde{x}_\ls(k)=\hat{x}(k),\ \varphi(k)=(I-GF)\epsilon(k).
	\end{equation*}
\end{lemma}
\begin{proof}
	Consider the following least square problem
	\begin{align}\label{pb:least_square_orign}
	\underset{\tilde{x}_\ls (k)}{\operatorname{minimize}}\quad \frac{1}{2} \left({Y}(k)-H \tilde{x}_\ls(k)\right){'} \tilde{M}^{-1} \left({Y}(k)-H \tilde{x}_\ls(k)\right) . 
	\end{align}
	Based on Theorem 2 in \cite{liuxinghua-TAC2020}, the solution to problem \eqref{pb:least_square_orign} is equivalent to Kalman estimation. It is sufficient to prove that problem \eqref{pb:least_square} and \eqref{pb:least_square_orign} are equivalent.
	Define 
	$$
	\Mc\triangleq
	\begin{bmatrix}
	I_{mn} & \mathbf{0}_{mn\times mn_s} \\ 
	\Nc		
	& I_{mn_s} 
	\end{bmatrix}
	\in \Rb^{m(n+n_s)\times m(n+n_s) }.
	$$
	Consider the objective function of problem \eqref{pb:least_square_orign} added by a constant term\footnote{$Y(k)$ is fixed for each $k$ in the optimization problem. For legibility, the time index $(k)$ is omitted.}:
	\begin{align}
	&\frac{1}{2} ({Y} - H\tilde{x}_{\ls} ){'} \tilde{M}^{-1} ({Y} - H\tilde{x}_{\ls} ) +\frac{1}{2}  Y'\Nc'\Nc Y =\frac{1}{2}\begin{bmatrix}
	{Y} - H\tilde{x}_{\ls} \\ \Nc Y
	\end{bmatrix}^{'}
	\begin{bmatrix}
	\tilde{M}^{-1} & \mathbf{0} \\
	\mathbf{0} &  I
	\end{bmatrix}
	\begin{bmatrix}
	{Y} - H\tilde{x}_{\ls} \\ \Nc Y
	\end{bmatrix}. \label{eq:expand_mn_to_mn+ms}
	\end{align}
	Notice that 
	\begin{equation*}
	\begin{bmatrix}
	{Y} - H\tilde{x}_{\ls} \\
	\Nc Y
	\end{bmatrix}=\Mc
	\begin{bmatrix}
	{Y} - H\tilde{x}_{\ls} \\
	\Nc H \tilde{x}_{\ls}
	\end{bmatrix},
	\end{equation*}
	and (\ref{eq:expand_mn_to_mn+ms}) can be written as 
	\begin{align}\label{eq:obj_function}
	&\frac{1}{2}
	\left(\Mc
	\begin{bmatrix}
	{Y} - H\tilde{x}_{\ls} \\
	\Nc H \tilde{x}_{\ls}
	\end{bmatrix}
	\right)^{'}
	\begin{bmatrix}
	\tilde{M}^{-1} & \mathbf{0} \\
	\mathbf{0} &  I
	\end{bmatrix}
	\left(\Mc
	\begin{bmatrix}
	{Y} - H\tilde{x}_{\ls} \\
	\Nc H \tilde{x}_{\ls}
	\end{bmatrix}
	\right) 
	=\frac{1}{2}
	\begin{bmatrix}
	{Y} - H\tilde{x}_{\ls} \\
	\Nc H \tilde{x}_{\ls}
	\end{bmatrix}^{'}
	\Wc
	\begin{bmatrix}
	{Y} - H\tilde{x}_{\ls} \\
	\Nc H \tilde{x}_{\ls}
	\end{bmatrix} . 
	\end{align}
	Substituting $\varphi$ in \eqref{pb:least_square} with ${Y}-H\tilde{x}_{\ls}$ leads to \eqref{eq:obj_function}. Thus, optimizing unconstrained problem with objective function  \eqref{eq:obj_function} is equivalent to optimizing problem \eqref{pb:least_square}.  $\square$ 
	\end{proof}

Based on least square problem \eqref{pb:least_square}, we present the following optimization problem whose solution $\tilde{x}(k)$ is our proposed secure estimation. The constant $\gamma$ is a non-negative adjustable parameter.
\begin{subequations}\label{pb:resilient_LASSO}
	\begin{align}
	\underset{{\tilde{x}}(k), \mu(k),\nu(k)}{\text{minimize}}&\quad \frac{1}{2} 
	\begin{bmatrix}
	\mu(k) \\
	\Nc H \tilde{x}(k)
	\end{bmatrix}^{'} \Wc
	\begin{bmatrix}
	\mu(k) \\
	\Nc H \tilde{x}(k)
	\end{bmatrix} + \gamma\left\|\nu(k)\right\|_1  \\
	\text { subject to }&\quad
	{Y} (k)= H \tilde{x}(k)+\mu(k)+\nu(k) .  
	\end{align}
\end{subequations}
%The following subsection characterizes the estimation $\tilde{x}(k)$ solved from problem \eqref{pb:resilient_LASSO} in the absence and in the presence of attack.

%We have the following results quantifying the performance of our proposed secure estimator.
%
%\begin{theorem}\label{th:att_obs}
%In the presence of arbitrary $(p,m)$-sparse attack, if the system $(A,C)$ is $2p$-sparse observable, the estimation $\check{x}(k)$ solved from (\ref{pb:lasso}) is secure.
%\end{theorem}


%the estimation difference between $\tilde{x}(k)$ solved from (\ref{pb:lasso}) and oracle Kalman estimation $\hat{x}(k)$ satisfies
%\begin{equation}\label{eq:diff_upper_bound}
%	\|\tilde{x}(k)-\hat{x}(k)\|_\ift\leq \Gamma(k)+\left(\gamma+\gamma_0(k) \right) \left\|\tilde{M}\right\|_\ift,
%\end{equation}
%where
%\begin{align*}
%	\Gamma(k) &\triangleq \max_{j\in\{1,\cdots,n\}}\left\{ \max_{i_1,i_2\in \Ec_j} \left| \left[P_{i_1} \zeta^o_{i_1}(k)\right]_j- \left[P_{i_2} \zeta^o_{i_2}(k)\right]_j \right| \right \}, \\
%	\gamma_0(k)&\triangleq \left\| \tilde{M}^{-1}\left(I-GF\right) \epsilon^o(k)\right\|_{\infty},
%\end{align*}
%with $\Ec_j$ defined in \eqref{eq:def_Ec} and $[\cdot]_j$ is the $j$-th element of a vector.
%Moreover, $\Gamma(k)$ and $\gamma_0(k)$ have bounded variance for all $k\in\Zb^+$ and thus our proposed estimation $\tilde{x}(k)$ is secure. 
%\end{theorem}



%\section{Secure Estimation with Sparse Detectability}
%In this section, we propose a new design of secure estimation based on previous optimization problem. The secure condition is relaxed to $2p$-sparse detectable by separately handle stable states in the optimization problem. We then prove $2p$-sparse detectability is necessary by showing that if the system is not $2p$-sparse detectable, there exists an attack that no estimator can be secure in the presence of $p$ such corrupted sensors.
%
%\subsection{Secure Estimation Design via State Decomposition}
%
%
%%without loss of generality, we assume the unstable entries take the position of first $n_u$ entries, i.e. $\Uc=\{1,2,\cdots,n_u\}$ and $\Sc=\{n_u+1,\cdots,n\}$.
%
%The following corollary directly comes from Theorem \ref{th:span}.
%\begin{corollary}\label{co:span_unstable}
%\end{corollary}
%In Corollary \ref{co:span_unstable}, the matrix $G_i^\Uc$ is transformed into canonical form while $G_i^\Sc$ is not. In the following we design an estimation scheme where estimations of stable states are always secure. Based on this design, the condition of $2p$-sparse observable can be relaxed to $2p$-sparse detectable.
%	The reason is that the stable states will converge to zero and we can leverage this property to guarantee the resilience of the estimation of stables states without any knowledge about the attack.
%	In order to achieve this, we need some transformation on problem (\ref{pb:compact_least_square}). The result is that the sufficient condition of resilience only relies on $H_{ss,i}$.

%We need the following notations. 
%Define the vector of unstable states and stable states as
%\begin{equation}\label{eq:def_x_u}
%x_u\triangleq [x_1,\cdots,x_{n_u}]{'}, \ x_s\triangleq [x_{n_u+1},\cdots,x_{n}]{'}.
%\end{equation}


The following theorem characterizes the performance of our proposed estimator when the attacker is absent. 
The proof is provided in Appendix \ref{ap:main}.
\begin{theorem}\label{th:no_attack}
	In the absence of attack, if the parameter $\gamma$ in problem (\ref{pb:resilient_LASSO}) satisfy
	\begin{align}\label{eq:kalman_cond}
	\left\|\Wc \begin{bmatrix}
	\left(I-GF\right)\epsilon(k) \\
	\Nc H \hat{x}(k)
	\end{bmatrix}\right\|_\ift\leq\gamma, 
	\end{align}
	then our proposed estimation $\tilde{x}(k)$ is equivalent to the estimation of fixed gain Kalman filter defined in (\ref{eq:fix_gain_kalman}), i.e.,
	\begin{equation}\label{eq:eq_to_kalman}
	\tilde{x}(k)=\hat{x}(k).
	\end{equation}
\end{theorem}
Noticing that $\epsilon(k)$ is a stationary Gaussian process after extended period of time and $\hat{x}(k)$ is a Gaussian random variable, the probability that \eqref{eq:kalman_cond} holds is determined only by system parameter $A,B,C,Q,R,\gamma$ given input $u(k)$, and can be explicitly calculated given these parameters.
By tuning design parameter $\gamma$, the probability of recovering the Kalman estimation can be adjusted.

	

In order to quantify the estimation difference between the attack is absent and the attack is present, we consider the following local estimation and Kalman estimation without attack:
\begin{align}
\zeta^o_i (k+1) &= \Pi \zeta^o_i (k) + \mathbf{1}_n z_i (k+1) + (G_i-\mathbf{1}_nC_i)Bu(k), \label{eq:def_zetare} \\
\hat{x}^o (k+1)& = (I-K C) \left(A \hat{x}^o(k)+Bu(k)\right) + K z (k+1),\label{eq:def_xhatre}
\end{align}
where $z(k)=Cx(k)+v(k)$ is the original (unmanipulated) measurement.
Define $\epsilon^o_{i}(k)$ correspondingly as $\epsilon^o_{i}(k)\triangleq \zeta^o_i(k)-G_ix(k)$.

\begin{theorem}\label{th:main}
In presence of arbitrary admissible $(p,m)$-sparse attack, if the system $(A,C)$ is $2p$-sparse detectable, then 
the estimation difference between $\tilde{x}(k)$ solved from (\ref{pb:resilient_LASSO}) and oracle Kalman estimation $\hat{x}^o(k)$ satisfies
\begin{equation}\label{eq:diff_upper_bound}
\left|[\tilde{x}(k)]_j-[\hat{x}^o(k)]_j\right|\leq
\begin{cases*}
\max_{i_1,i_2\in \Ec_j} \left| \left[P_{i_1} \zeta^o_{i_1}(k)\right]_j- \left[P_{i_2} \zeta^o_{i_2}(k)\right]_j\right| + \left(\gamma+\gamma^o(k) \right) \left\|\Fc\right\|_\ift ,\ j\in\Uc\\\gamma \cdot \left\|\Fc\right\|_\ift+\left| [\hat{x}^o(k)]_j \right|,\ j\in\Sc
\end{cases*},
%	\|\tilde{x}(k)-\hat{x}^o(k)\|_\ift\leq \Gamma(k)+\left(\gamma+\gamma^o(k) \right) \left\|\Fc\right\|_\ift,
\end{equation}
where
\begin{align*}
	\gamma^o(k)&\triangleq \left\|\Wc \begin{bmatrix}
	\left(I-GF\right)\epsilon^o(k) \\
	\Nc H \hat{x}^o(k)
	\end{bmatrix}\right\|_\ift,\\
	\Fc	&\triangleq
	\left(
	\begin{bmatrix}
	I_{mn} & \mathbf{0} \\
	\mathbf{0}  &  \Lc H{'} \Nc{'}
	\end{bmatrix}
	\Wc
	\begin{bmatrix}
	I_{mn} & \mathbf{0} \\
	\mathbf{0}  &  \Nc H \Lc{'}
	\end{bmatrix}
	\right)^{-1}
	\begin{bmatrix}
	I_{mn} & \mathbf{0} \\ \mathbf{0} &\Lc H{'}
	\end{bmatrix},\\
	\Lc&\triangleq 
	\begin{bmatrix}
	\mathbf{0}_{n_s\times n_u} & I_{n_s}
	\end{bmatrix}.
\end{align*}
with $\Ec_j$ defined in \eqref{eq:def_Ec} and $[\cdot]_j$ is the $j$-th element of a vector.
Since the oracle Kalman estimation is a stable estimation of system state $x(k)$, and the upper bounds have bounded variance for all $k\in\Zb^+$, our proposed estimation $\tilde{x}(k)$ is secure. 		
\end{theorem}

Under assumption \ref{as:geo_unstable}, if the system is $2p$-sparse detectable, our proposed estimator is secure. The maximum estimation difference from oracle Kalman filter is shown in \eqref{eq:diff_upper_bound}.
Theorem \ref{th:main} indicates smaller $\gamma$ leads to lower estimation difference upper bound in the presence of attack. However, based on Theorem \ref{th:no_attack}, smaller $\gamma$ decreases probability of recovering the optimal Kalman estimation in the absence of attack. The choice of $\gamma$ represents the trade-off between the performance in normal operation and the performance under attack. 

Moreover, since sparse detectability index only requires simple computation according to Corollary \ref{co:sparse_obs}, our work reduces the complexity of evaluating system vulnerability significantly under the assumption of geometric multiplicity.
For general $A$ that has unstable eigenvalues with geometric multiplicity larger than 1, computing sparse observability is an NP-hard problem \cite{yanwen_CDC19}\cite{sandberg_TAC2014}, and there is no computational efficient solution unless P$=$NP. Simultaneously, for algorithm online operation, the computing of estimation involves solving a convex optimization problem based on LASSO \cite{LASSOTibshirani}, which can be done efficiently.
	
%	\begin{remark}
%		Condition (\ref{cond:suff}) reduces the sufficient condition in \cite{liuxinghua-IFAC}\cite{handuo_tac} in two ways.
%		On the one hand, by normalizing $G_i$ to $H_i$, condition (\ref{cond:suff}) is easily verified by checking the number of $1$ in first $n_u$ columns of $H_i$. However in previous works, the complexity of verifying the condition is significantly high.
%		On the other hand, the part of $H_i$ that corresponding to stable states do not affect the estimator resilience because the transofrmation (\ref{eq:expand_mn_to_mn+ms})(\ref{eq:obj_function}) extract the stable states $\tilde{x}_s$ to appear explicitly in the objective function (\ref{pb:resilient_LASSO}) and thus is bounded due to the nature of LASSO~\cite{LASSOTibshirani}.
%		
%	\end{remark}
	
The following Theorem proves that $2p$-sparse detectability is necessary for the existence of a secure estimation.
% which 
%indicates our proposed estimation scheme provides a secure estimation whenever it is possible in the presence of $(p,m)$-sparse attack.
\begin{theorem}[\hspace{-0.001pt}\cite{yorie} Theorem 1]\label{th:funda_lim}
	If the system is not $2p$-sparse detectable, there exists a $(p,m)$-sparse attack strategy that no estimator is secure.
\end{theorem}
In view of Theorem \ref{th:funda_lim}, our proposed estimator achieves the fundamental limit of secure estimation problem, i.e., provides a secure estimation whenever the system is possible to be securely estimated. 
The performance of our proposed estimator is corroborated by the numerical simulation in the next section.

%In view of this work, we provide a secured information fusion scheme whenever the system is $2p$-sparse detectable and it is optimal in the absence of attacks. If the system is not $2p$-sparse detectable, we can prove that there does not exist a secure estimator.
%We can calculate the observability or detectability index
%If the system is $2p$-detectable, the proposed estimator is resilient to $(p,m)$-sparse attack.
%If the system is not $2p$-detectable, we can prove that there does not exist an resilient estimation in the presence of $(p,m)$-sparse attack.
%In the absence of attack, our proposed estimator coincides with Kalman estimator and is thus optimal in the sense of least mean square error.
 





\section{Illustrative Example}\label{sec:sim}
We use an inverted pendulum for the numerical simulation\footnote{The corresponding code is posted on \texttt{https://github.com/} \texttt{zs-li/resilient\_dynamic\_estimation}.}. The physical parameters are illustrated in Fig. \ref{fig:invpen}. 
%the The mass of the cart and the mass of the pendulum are both $1$ kilogram. The length of pendulum is $1$ meter and the moment of inertia of the pendulum is $1/3$ $kg\cdot m^2$.
The control input $u(k)$ is the force applied on the cart, and we assume that there is no frictions of any form.
The state $x_1,x_2,x_3,x_4$ represent cart position coordinate, cart velocity, pendulum angle from vertical and pendulum angle velocity respectively. 
\begin{figure}[htpb]
	\centering
	\input{inv_pen.tex}
	\caption{Illustration of the inverted pendulum.}\label{fig:invpen}
\end{figure}

Consider the system linearized at $x_3=x_4=0$, and we sample the continuous-time linear system periodically with sampling interval $T_s=0.02$ seconds. 
The system equation is:
\begin{align*}
x(k+1)=\begin{bmatrix}
1  &   2.0\cdot 10^{-2}  &  -2.0\cdot 10^{-4}  &  1.9\cdot 10^{-5}\\
0  &   1.0\cdot 10^{0}   & -2.0\cdot 10^{-2}  &   1.8\cdot 10^{-3}\\
0  &   1.0\cdot 10^{-5} &   1.0\cdot 10^{0} &   2.0\cdot 10^{-2}\\
0  &   1.0\cdot 10^{-3}&  2.1\cdot 10^{-1}  &  9.8\cdot 10^{-1}
\end{bmatrix}x(k)+\begin{bmatrix}
2.0\cdot 10^{-4}\\
2.0\cdot 10^{-2}\\
-2.0\cdot 10^{-4}\\
-2.0\cdot 10^{-2}
\end{bmatrix}
u(k)+w(k).
\end{align*}
\begin{align*}
y(k)=
\begin{bmatrix}
1& 0 &0 &0\\
1& 0 &0 &0\\
1& 0 &0 &0\\
0& 0 &1 &0
\end{bmatrix}x(k)+v(k)+a(k).
\end{align*}
The system dynamic matrix can be written as the following Jordan canonical form by an invertible linear transformation:
$$
\begin{bmatrix}
1.057 & 0 &  0 & 0\\
0  & 1 & 0 &  0\\
0  & 0 & 0.999 & 0  \\
0  & 0 & 0 &  0.925 
\end{bmatrix},
$$
and we consider the system after transformation. System matrix $A$ have four Jordan blocks with size $1\times1$ and the upper left two blocks have unstable eigenvalues. Therefore, the set of unstable states and stable states are $\Uc=\{1,2\},\Sc=\{3,4\}.$
The canonical form of $G_i^\Uc$ are 
\begin{align}
H_1^\Uc=H_2^\Uc=H_3^\Uc=\begin{bmatrix}
1 & 0 \\
0  & 1 \\
0  & 0   \\
0  & 0 
\end{bmatrix},\ H_4^\Uc=\begin{bmatrix}
0 & 0 \\
0  & 1 \\
0  & 0   \\
0  & 0 
\end{bmatrix}.
\end{align}
Only the first 3 sensors can observe unstable state 1, i.e., $\Ec_1=\{1,2,3\}$. All the four sensors can observe unstable state 2, i.e., $\Ec_2=\{1,2,3,4\}$.
Therefore, the system is 2-sparse detectable and our proposed estimator secure in the presence of 1 corrupted sensor. 
In the simulation, the noise covariances of the system are $Q=R=T_s^2\times\diag(0.1,0.1,0.01,0.01)$.
The initial state is assumed to be known by the estimator.
The controller of the system is designed as a Linear-Quadratic Regulator (LQR), and the feedback matrix is chosen as $K_{\rm lqr}=\begin{bmatrix}
	-8& -15& -115 &-32
 \end{bmatrix}.
$
%
%
%In the following we perform state transformation on the origin system to better analysis the observability structure.
%There exists a invertible matrix $U$ such that 
%
%In the following, we study the following system where $\bar{C}\triangleq CU$:
%	\begin{align*}
%		\bar{x}(k+1)&=\bar{A} \bar{x}(k)+U^{-1}w(k)+U^{-1}Bu(k), \\
%		y(k)&=\bar{C} \bar{x}(k)+v(k)+a(k).
%	\end{align*}


We first illustrate the performance of estimation on close-loop system where $u(k)=-K_{\rm lqr} x(k)$.
Fig. \ref{fig:close_loop} presents the performance of the estimation of system states in the absence of attack. Our proposed estimation substantially coincides with the Kalman estimation. The numerical difference attributes to large Gaussian noise that occurs occasionally which violates inequality \eqref{eq:kalman_cond} and error in numerical calculation.


\begin{figure}[htpb!]
	\centering
	\input{cl_no.tex}
	\caption{Estimation of states in the absence of attack. The initial state is $x(0)=[0,\ 1,\ 0,\ 1]{'}$. } \label{fig:close_loop}
\end{figure}

Fig \ref{fig:attack_signal} shows the injected attack signal on sensor 3 and the corresponding observations from sensor 3.
Fig. \ref{fig:close_loop_attack} demonstrates the estimation with the attack shown in Fig. \ref{fig:attack_signal}.
The attack $a_3(k)$ is a time-independent random value uniformly distributed on interval $(-1,1)$. As shown in the figure, Kalman estimation (denoted as red dashed line) has larger estimation error than our proposed estimation under the attack.

\begin{figure}[ht]
	\centering
	\input{at.tex}
	\caption{Attack signal and measurements of sensor 3. The attack signal is uniformly distributed in interval $(-1,1)$.  } \label{fig:attack_signal}
\end{figure}

\begin{figure}[ht]
	\centering
	\input{cl_at.tex}
	\caption{Estimation of states under attack on sensor 3. The attack signal is uniformly distributed in interval $(-1,1)$.  } \label{fig:close_loop_attack}
\end{figure}





Fig. \ref{fig:MSE} illustrates the estimation mean square error (MSE$=1/N\sum_{k=1}^{N}\left\|\hat{x}(k)-x(k)\right\|_2^2$) of our proposed estimator with varying tuning parameter $\gamma$ and varying attack magnitude with sensor 3 corrupted. 
The number of time steps is set as $N=200$.
The attack signal $a_3(k)$ is uniformly distributed in interval $(-\|a\|_\ift,\|a\|_\ift)$.
In Fig. \ref{fig:MSE_gamma}, the MSE of the oracle Kalman estimation, .i.e., Kalman estimation not affected by the attack, is illustrated by the red dashed line.
As shown in the figure, by properly choosing $\gamma$, the MSE of our proposed estimator is smaller than that of Kalman estimation (the red horizontal line), with the cost that MSE without attack is slightly larger. 
In Fig. \ref{fig:MSE_mag}, as the magnitude of attack signal increases, MSE of Kalman estimator increases significantly while our proposed secure estimator holds low MSE despite increasing magnitude of injected attack signal.
%
%\begin{figure}[ht]
%	\centering
%	\input{MSE.tex}
%	\caption{Estimation mean square error (MSE) in the presence of attack with varying tuning parameter $\gamma$ and varying attack magnitude. The left subplot adopts attack magnitude $\|a\|_\ift=1$ and the right subplot adpots $\gamma=10$.} \label{fig:MSE}
%
%\end{figure}

\begin{figure}[ht]
	\centering
	\begin{subfigure}{.48\textwidth}
		\centering
		\input{MSE_gamma.tex}
		\caption{Estimation mean square error (MSE) with varying tuning parameter $\gamma$. The attack magnitude is $\|a\|_\ift=1$.  } \label{fig:MSE_gamma}
	\end{subfigure}
\hspace{5pt}
	\begin{subfigure}{.48\textwidth}
		\centering
		\input{MSE_mag.tex}
		\caption{Estimation mean square error (MSE) with varying attack magnitude. The parameter $\gamma$ is set as $\gamma=10$. } \label{fig:MSE_mag}
	\end{subfigure}
	\caption{}
	\label{fig:MSE}
\end{figure}



%The estimation mean square error (MSE) in the absence and in the presence of attack is presented in Table \ref{tab:MSE}.
%The initial state is set to be $x(0)=\mathbf{0}$. When sensor 1 is under manipulation, the bias data is a random value uniformly distributed on interval $(-10,10)$. When sensor 4 is under manipulation, the bias data is a random value uniformly distributed on interval $(-\pi,\pi)$. The MSE of our proposed estimator is approximately the same as that of Kalman estimator in the absence of attack. In the presence of attack, the MSE of our proposed estimator is smaller.
%
%\begin{table}[h]
%	\caption{Mean square error of two estimators}\label{tab:MSE}
%	\begin{tabular}{c|c|c|c}
%	\hline 
%		Estimator & \makecell[c]{\small MSE without\\ attack} & \makecell[c]{\small MSE when \\ $\Ic=\{1\}$} &\makecell[c]{\small MSE when \\ $\Ic=\{4\}$} \\
%	\hline 
%		\makecell[c]{Kalman\\ estimator} & 0.0121 & 0.6652 & 2.8834 \\ 
%		\hline
%		\makecell[c]{Our proposed\\ estimator}  & 0.0122 & 0.4927 & 0.5025 \\
%		\hline 
%	\end{tabular}
%\end{table}





\section{Conclusion}\label{sec:conclusion}
This paper considers LTI system with Gaussian noise against sparse integrity attack on a subset of sensors. 
Under the geometric multiplicity assumption on stable eigenvalues of $A$, we propose an estimation scheme that is secure to $(p,m)$-sparse attack as long as the system is $2p$-sparse detectable. 
To achieve this, we prove that the span of the rows of $G^\Uc_i$ is equivalent to the observable space corresponding to unstable states, based on which the canonical form $H_i$ is designed. The proposed estimator is formulated as a convex optimization problem based on $H_i$, where by careful design, the estimation of stable states is always secured. 
Moreover, in the absence of attack, the proposed estimation coincides with Kalman estimation for certain probability, which can be adjusted by tuning parameter $\gamma$ to balance between the performance with and without attack.
We further prove that the $2p$-sparse detectable is necessary for secure estimation, which means our proposed estimator achieves this fundamental limit with good performance in the absence of attack and low computation complexity.
%For general $A$ without the geometric multiplicity assumption, calculating sparse observability index is NP-hard. 

%In previous works, we proposed a information fusion scheme by decomposing Kalman estimation into the linear combination of local estimates. 
%However, whether this estimator is resilient cannot be validated within polynomial time.
%In this paper, by introducing the assumption that all the eigenvalues of $A$ have geometric multiplicity 1, we prove that the structure of matrix $G_i$ is closely related to observability matrix of system $(A,C_i)$. This result enables us to design a secure estimator that is resilient to $p$ compromised sensors as long as the system is $2p$-sparse observable and this can be further relaxed to $2p$-sparse detectable. Moreover, the estimate coincides to Kalman estimate for certain probability in the absence of attack.  we design an algorithm that can compute sparse observability index in polynomial time. 
%However, when the geometric multiplicity is greater than 1, Lemma \ref{lm:span} no long holds and there are instances where $\rs(G_i)\neq \rs{O_i}$. We are currently investigating the solution in this case. Nevertheless, by decomposing the $n$ dimensional space into multiple orthogonal generalized eigenspaces, the problem of checking sparse observability can be significantly simplified. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
{\LARGE \bf \centering Appendix}
\appendix
\section{Proof of Theorem \ref{th:span}}\label{ap:span}
\begin{proof}
	Define the characteristic polynomial of $A$ as $p(x)=a_n x^n +\cdots+a_1 x +a_0$.
Define polynomial fraction  $q_\pi(x)$ with respect to constant $\pi$ as
$q_\pi(x)=\frac{p(x)-p(\pi)}{x-\pi}$ where $x\neq \pi$.
Therefore,
$$q_\pi(A)(A-\pi I) = p(A)-p(\pi)I=-p(\pi)I ,$$
where the last equality comes from Cayley-Hamilton Theorem.
As a result, when $\pi$ is not the eigenvalue of $A$, we have
\begin{align}\label{A-lambdaI}
(A-\pi I)^{-1}=-\frac{1}{p(\pi)} q_\pi(A).
\end{align}
In order to simplify notations, we define 
\begin{equation}\label{eq:bjk}
b_{j,k}\triangleq-\frac{1}{p(\pi_j)}\sum_{i=0}^{n-k-1} a_{i+k+1} \pi_j^i,
\end{equation}
where $\pi_j$ is the $j$-th diagonal element of $\Pi$, i.e., $j$-th eigenvalue of $A-KCA$ as defined in \eqref{eq:VLambda}.
According to (\ref{A-lambdaI}), the $j$-th row of matrix $G_i$ can be reformulated as
$$C_{i} A\left(A-\pi_{j} I\right)^{-1}=
\begin{bmatrix}
b_{j,0} & b_{j,1} & \cdots  & b_{j,n-1} 
\end{bmatrix} O_i A.$$
Therefore, $G_i$ can be interpreted as follows
\begin{align*}
G_i = \begin{bmatrix}
b_{1,0} & b_{1,1} & \cdots  & b_{1,n-1} \\
b_{2,0} & b_{2,1} & \cdots  & b_{2,n-1} \\
\vdots & \vdots & \ddots  & \vdots \\
b_{n,0} & b_{n,1} & \cdots  & b_{n,n-1} 
\end{bmatrix}
O_i A 
= & \mathcal{D}_1\mathcal{D}_2\mathcal{D}_3 O_i A , %\label{eq:GandOA}		
\end{align*}
where $\mathcal{D}_1\triangleq\text{diag}\left(-\frac{1}{p(\pi_1)},-\frac{1}{p(\pi_2)},\cdots,-\frac{1}{p(\pi_n)}\right)$,
\begin{align*}
\mathcal{D}_2\triangleq
\begin{bmatrix}
\pi_1^{n-1} & \pi_1^{n-2} & \cdots  & 1 \\
\pi_2^{n-1} & \pi_2^{n-2} & \cdots  & 1 \\
\vdots & \vdots & \cdots  & \vdots \\
\pi_n^{n-1} & \pi_n^{n-2} & \cdots  & 1
\end{bmatrix}, 
\mathcal{D}_3\triangleq
\begin{bmatrix}
a_n & 0 & \cdots &   0 \\
a_{n-1} & a_n & \cdots &   0 \\
\vdots & \vdots & \ddots  & \vdots \\
a_1 & a_2 & \cdots  & a_n 
\end{bmatrix}.
\end{align*}
According to Assumption \ref{as:distinct_eigvalue}, all $\pi_j$ are distinct eigenvalues and they are not the eigenvalues of $A$, i.e. the diagonal matrix $\mathcal{D}_1$ and the Vandermonde matrix $\mathcal{D}_2$ are invertible. Moreover, $a_n=1$. Therefore, the lower triangular Toeplitz matrix $\mathcal{D}_3$ is invertible and thus $\rs(G_i)=\rs(O_i A)$. 		
We continue to prove $\rs(O_i)=\rs(O_i A)$. Considering that $A^n=-a_{n-1}A^{n-1}-\cdots-a_0 I$, one obtains the following equation \eqref{eq:O_OA}.
\begin{equation}
\label{eq:O_OA}
O_i A=
\begin{bmatrix}
0 & 1 & 0 &  \cdots & 0 \\
0 & 0 & 1 &  \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 &  \cdots & 1 \\
-a_0 & -a_1 & -a_2 & \cdots &  -a_{n-1}
\end{bmatrix}
O_i .
\end{equation}	%\vspace{-20pt}
According to Assumption \ref{as:distinct_eigvalue}, $A$ is invertible and $a_0=(-1)^n\det(A)\neq 0$, which leads to the equation that $\rs(O_i)=\rs(O_i A)$.
As a result, $\rs(G_i^\Uc)$=$\rs(O_i^\Uc)$. We continue to prove that $\rs(O_i^\Uc)=\rs(H_i^\Uc).$
Since $A_1$ is assumed to be in the Jordan canonical form and all eigenvalues have geometric multiplicity 1, one can verify that nonzero columns of $O^\Uc_i$ are linear independent. Therefore, $i\in\Ec_j$ is equivalent to that $j$-th column of $O_i$ is non-zero, i.e., $O^\Uc_i$ has the same row-span with the canonical form $H^\Uc_i$.
$\square$
\end{proof}

%\section{Proof of Theorem \ref{th:att_obs}}\label{ap:att_obs}
%
%\begin{proof}[Proof of Theorem \ref{th:att_obs}]
%	In view of Theorem \ref{th:TAC} and Lemma \ref{lm:least_square}, it suffices to prove that the following two propositions are equivalent:
%	\begin{enumerate}
%		\item The system is $2p$-sparse observable.
%		\item The following inequality holds for all $x \neq \mathbf{0}$, $x\in\Rb^n$:
%		\begin{equation}\label{eq:proof_cond}
%		\sum_{i \in \mathcal{I}}\left\|H_{i} x\right\|_{1}<\sum_{i \in \mathcal{I}^{c}}\left\|H_{i} x\right\|_{1}, \quad \forall\ \Ic\subset \Oc, |\mathcal{I}|\leq p .
%		\end{equation}
%	\end{enumerate}
%	Based on the form of $H_i$ in Theorem \ref{th:span}, inequality \eqref{eq:proof_cond} can be written as 
%	\begin{equation*}
%	\sum_{j=1}^{n} \sum_{i \in \mathcal{I}\cap\Ec_j}|x_j|<\sum_{j=1}^{n} \sum_{i \in \mathcal{I}^c\cap\Ec_j}|x_j| 
%	\end{equation*}
%	or equivalently 
%	$$
%	\sum_{j=1}^{n} c_j(\Ic)\cdot|x_j|<\sum_{j=1}^{n} h_j(\Ic)\cdot|x_j| .
%	$$
%	If the system is $2p$-sparse observable, we have $c_j(\Ic)<h_j(\Ic)$ for all $j\in\{1,2,\cdots,n\}$. Thus, $\sum_{j=1}^{n} \left(h_j(\Ic)-c_j(\Ic)\right)\cdot|x_j| >0$ holds for all $x\neq \mathbf{0}$.
%	If the system is not $2p$-sparse observable, there exists $\Ic^*$ with $|\Ic^*|=p$ and $j^*$ such that $c_{j^*}(\Ic^*)>h_{j^*}(\Ic^*)$. One can design $x\neq \mathbf{0}$ such that 
%	$$\left(c_{j^*}(\Ic^*)-h_{j^*}(\Ic^*)\right)\cdot|x_{j^*}|> \sum_{j\neq j^*}\left(h_{j}(\Ic^*)-c_{j}(\Ic^*)\right)\cdot|x_j| .$$
%	Therefore, condition \eqref{eq:proof_cond} is violated and the proof is completed. $\square$
%\end{proof}

\section{Proof of Theorem \ref{th:no_attack}}\label{ap:ap_no_attack}
\begin{proof}[Proof of Theorem \ref{th:no_attack}]
	
	Considering the KKT condition of problem \eqref{pb:resilient_LASSO}, one obtains that if 
	$$\left\|\Wc \begin{bmatrix}
	\mu(k) \\
	\Nc H \tilde{x}(k)
	\end{bmatrix}\right\|_\ift\leq\gamma,$$ then the solution $\nu(k)$ satisfy that $\nu(k)=\mathbf{0}$. In this scenario, solutions to problem \eqref{pb:resilient_LASSO} and problem \eqref{pb:least_square} are equivalent and the solution $\tilde{x}(k),\mu(k),\nu(k)$ satisfy
	\begin{equation}\label{eq:lasso_recover}
	\tilde{x}(k)=\tilde{x}_\ls(k)=\hat{x}(k),\ \mu(k)=\varphi(k),\ \nu(k)=\mathbf{0}.
	\end{equation}
	According to Lemma \ref{lm:least_square}, the solution $\varphi(k)$ of problem \eqref{pb:least_square} satisfy the following equation:
	\begin{equation}\label{eq:ls_recover}
	\tilde{x}_\ls(k)=\hat{x}(k),\ \varphi(k)=(I-GF)\epsilon(k),
	\end{equation}
	where $\hat{x}(k)$ is the fixed gain Kalman estimation defined in \eqref{eq:fix_gain_kalman}.
	Combining \eqref{eq:ls_recover} and \eqref{eq:lasso_recover}, result in Theorem \ref{th:no_attack} is obtained. $\square$
\end{proof}

\section{Proof of Theorem \ref{th:main}}\label{ap:main}
Before proving Theorem \ref{th:main}, we need the following Lemma.
Define the number of honest sensors and compromised sensors (w.r.t. compromised set $\Ic$) that can observe state $j$ as:
\begin{align*}
h_j(\Ic)\triangleq |\Ec_j\cap \Ic^c|, \
c_j(\Ic)\triangleq |\Ec_j\cap \Ic|.
\end{align*}
We have the following lemma quantifying the property of $h_j(\Ic)$ and $c_j(\Ic)$.  
\begin{lemma}\label{lm:cj<hj}
	The following two propositions are equivalent.
	\begin{enumerate}
		\item The system is $2p$-sparse observable.
		\item For any $\Ic$ with $|\Ic|=p$, the inequality $c_j(\Ic)<h_j(\Ic)$ holds for all $j\in\{1,2,\cdots,n\}$.
	\end{enumerate}
\end{lemma}
\begin{proof}[Proof of Lemma \ref{lm:cj<hj}]
	We prove the contrapositive of (1)$\Rightarrow$(2). Supposing that there exists $j^*$ and $\Ic^*$ with $|\Ic^*|=p$ such that $ c_{j^*}(\Ic^*)\geq h_{j^*}(\Ic^*)$, then
	$h_{j^*}(\Ic^*)\leq c_{j^*}(\Ic^*)\leq |\Ic^*|=p$. Noticing that $c_j(\Ic)+h_j(\Ic)=|\Ec_j|$ holds for all $\Ic$, we have $|\Ec_{j^*}|\leq 2p$. 
	There exists set $\Ac$ that satisfy $\Ac\supseteq\Ec_{j^*}$ and $|\Ac|=2p$.
	According to the definition of $\Ec_{j^*}$, there exists no sensor in set $\Oc\setminus \Ac$ who can observe state $j^*$, i.e.,
	\begin{equation*}
	e_{j^*}\notin \rs(O_i),\ \forall i\in\Oc\setminus \Ac.
	\end{equation*}
	As a result, system $(A,C_{\Oc\setminus\Ac})$ is not $2p$-sparse observable according to Definition \ref{df:sparse_obs}. 
	
	We proceed to prove (2)$\Rightarrow$(1). 
	Since for any $\Ic$ with $|\Ic|=p$, $h_j(\Ic)>c_j(\Ic)\geq 0$, the system sparse observability index is at least $p$. Therefore, for each $j\in\{1,2,\cdots,n\}$, there exists an $\Ic^*$ such that $c_j(\Ic^*)=p$, and thus $|\Ec_j|=h_j(\Ic^*)+c_j(\Ic^*)\geq 2p+1$. According to the definition $\Ec_j$, there are at least $2p+1$ sensors that can observe sensor $j$, and the system is $2p$-sparse observable.	
	$\square$
\end{proof}

We need the following notations for the proof.
Define the unstable part and stable parts of $x$ as the following where $x_u\in\Cb^{n_u\times 1}$ and $x_s\in\Cb^{n_s\times 1}$. Similarly, divide matrix $H_i$ into four parts based on Theorem \ref{th:span} where $H_{uu,i}\in\Cb^{n_u\times n_u}$ and $H_{ss,i}\in\Cb^{n_s\times n_s}$.
\begin{align*}
x = 
\left[
\begin{array}{c}
x_u\\x_s
\end{array}
\right],\
%\begin{array}{l}
%\hspace{-6pt}\left. \right\} \text{first $n_u$ entries}\\
%\hspace{-6pt}\left. \right\} \text{last $n_s$ entries}
%\end{array} .\\
	H_i=\begin{bmatrix}
H_{uu,i}	& 	H_{us,i} \\
\mathbf{0}_{n_s\times n_u} & H_{ss,i}
\end{bmatrix} .
\end{align*}
Define $\eta_{i}\triangleq P_i\zeta_{i}$.
Similar to $x$, $\tilde{x}$ and $\eta_i$ are also divided to $\tilde{x}_u,\tilde{x}_s,\eta_{i,u},\eta_{i,s}$ in the same way.

	\begin{proof}[Proof of Theorem \ref{th:main}]
	Consider the KKT condition of problem (\ref{pb:resilient_LASSO}) and denote the dual variables for equation constraints as $\lambda=[\lambda_1{'},\cdots,\lambda_m{'}]{'}\in \Cb^{mn\times 1}$:	
	\begin{align}
	(\tilde{M}^{-1}+\Nc{'}\Nc)\mu+\Nc{'} \Nc H\tilde{x} - \lambda &= \mathbf{0}, \label{eq:KKT1}\\
	H{'} \Nc{'}\Nc\mu+H{'} \Nc{'} \Nc H\tilde{x} -  H{'}\lambda &= \mathbf{0}, \label{eq:KKT2} \\
	\gamma \cdot  \tilde{\nu} - \lambda &= \mathbf{0}, \label{eq:KKT3} \\
	{Y} - H \tilde{x} - \mu - \nu &= \mathbf{0},  \label{eq:KKT4}
	\end{align}
	where $\tilde{\nu}$ belongs to the subgradient of $\|\nu\|_1$, i.e., for the $i$-th entry:
	\begin{align*}
	\begin{cases}
	[\tilde{\nu}]_i=-1 ,& \ [\nu]_i<0 \\
	[\tilde{\nu}]_i=1 , &\ [\nu]_i>0  \\
	[\tilde{\nu}]_i\in\left[-1,1\right],& \ [\nu]_i=0 
	\end{cases}.
	\end{align*}
	
	Combining (\ref{eq:KKT1}) and (\ref{eq:KKT2}) leads to:
	\begin{equation}\label{eq:KKT12}
	\begin{bmatrix}
	\tilde{M}^{-1}+\Nc{'}\Nc & \Nc{'} \Nc H\\
	H{'} \Nc{'} \Nc  & H{'} \Nc{'} \Nc H
	\end{bmatrix}
	\begin{bmatrix}
	\mu \\ \tilde{x}
	\end{bmatrix}=
	\begin{bmatrix}
	\lambda \\ H{'} \lambda 
	\end{bmatrix}.
	\end{equation}
	According to the definition of $\Nc$, the first $n_u$ rows of $H{'} \Nc{'} \Nc$ are zeros. Therefore, we extract the non-zeros part of equation (\ref{eq:KKT12}) in the following:
	\begin{equation}\label{eq:KKT12_nonzero}
	\begin{bmatrix}
	\tilde{M}^{-1}+\Nc{'}\Nc & \Nc{'} \Nc H \Lc{'}\\
	\Lc H{'} \Nc{'} \Nc  &  \Lc H{'} \Nc{'} \Nc H \Lc{'}
	\end{bmatrix}
	\begin{bmatrix}
	\mu \\ \tilde{x}_s
	\end{bmatrix}=
	\begin{bmatrix}
	\lambda \\ \Lc H{'} \lambda 
	\end{bmatrix}.
	\end{equation}
	where $\Lc\triangleq 
	\begin{bmatrix}
	\mathbf{0}_{n_s\times n_u} & I_{n_s}
	\end{bmatrix}.
	$
	%Notice that
	%\begin{align}
	%&\Lc H{'} \Nc{'} \Nc H \Lc{'} 
	%- \Lc H{'} \Nc{'} \Nc(\tilde{M}^{-1}+\Nc{'}\Nc)^{-1} \Nc{'} \Nc H \Lc{'} \notag \\
	%= &\Lc H{'} \Nc{'}  \left(I -\Nc(\tilde{M}^{-1}+\Nc{'}\Nc)^{-1}\Nc{'} \right)  \Nc H \Lc{'} . \label{eq:schur_comp}
	%\end{align}
	%Since Iâˆ’\Nc(M~âˆ’1+\NcâŠ¤\Nc)âˆ’1\NcâŠ¤ is invertible and \LcHâŠ¤\NcâŠ¤ is row full-rank (???) is also invertible due to the Frobenius rank inequality.
	%Therefore, according to the result of Schur complement, matrix on the left of (???) is invertible.
	Rewrite (\ref{eq:KKT12_nonzero}) as:
	\begin{align}\label{eq:KKT12_matrix}
	\left(
	\begin{bmatrix}
	I_{mn} & \mathbf{0} \\
	\mathbf{0}  &  \Lc H{'} \Nc{'}
	\end{bmatrix}
	\Wc
	\begin{bmatrix}
	I_{mn} & \mathbf{0} \\
	\mathbf{0}  &  \Nc H \Lc{'}
	\end{bmatrix}
	\right)
	\begin{bmatrix}
	\mu \\ \tilde{x}_s
	\end{bmatrix}=
	\begin{bmatrix}
	I_{mn} & \mathbf{0} \\
	\mathbf{0}  &  \Lc H{'}
	\end{bmatrix}
	\lambda .
	\end{align}
	Notice that $\Wc$ is positive definite and $\begin{bmatrix}
	I_{mn} & \mathbf{0} \\
	\mathbf{0}  &  \Lc H{'} \Nc{'}
	\end{bmatrix}$
	is full row-rank,
%	\footnote{
%		$\Lc H{'} \Nc{'}=
%		\begin{bmatrix}
%		H{'}_{ss,1} & H{'}_{ss,2} & \cdots & H{'}_{ss,m} % !!!NOtice that H_{ss,i}=G_{ss,i}, if this matrix not full row fank, then $G{'}_{ss,1} & G{'}_{ss,2}$ is row rank defected and there are unobservable stable states.
%		\end{bmatrix}
%		$ is row full-rank due to the fact that for every stable state, there is at least one sensor who is able to observe the state.
%	}, 
	due to the Frobenius rank inequality, the matrix on the left of (\ref{eq:KKT12_matrix}) is also invertible, and thus the following matrix is well-defined:
	\begin{align}\label{eq:def_H}
	\Fc	\triangleq
	\left(
	\begin{bmatrix}
	I_{mn} & \mathbf{0} \\
	\mathbf{0}  &  \Lc H{'} \Nc{'}
	\end{bmatrix}
	\Wc
	\begin{bmatrix}
	I_{mn} & \mathbf{0} \\
	\mathbf{0}  &  \Nc H \Lc{'}
	\end{bmatrix}
	\right)^{-1}
	\begin{bmatrix}
	I_{mn} & \mathbf{0} \\ \mathbf{0} &\Lc H{'}
	\end{bmatrix}.
	\end{align}
	
	%Sufficient condition of (???) is:
	%\begin{align}\label{eq:KKT2_2}
	%	\Nc \mu + \Nc H \tilde{x} - \frac{1}{2}(\Nc^\dag){'} \lambda = \mathbf{0} 
	%\end{align}
	%where \Nc\dag is the pseudo-inverse of \Nc.
	%Combining (???) and (???) leads to:
	%\begin{equation}\label{eq:KKT12}
	%	\begin{bmatrix}
	%		\tilde{M}^{-1}+\Nc{'}\Nc & \Nc{'} \\
	%		\Nc & I
	%	\end{bmatrix}
	%	\begin{bmatrix}
	%		\mu \\ \Nc H \tilde{x}
	%	\end{bmatrix}=\frac{1}{2}
	%	\begin{bmatrix}
	%		\lambda \\ (\Nc^\dag){'} \lambda 
	%	\end{bmatrix}.
	%\end{equation}
	
	According to (\ref{eq:KKT3}), $\|\lambda\|_\infty \leq \gamma$. 
	Therefore we have the following from (\ref{eq:KKT12_matrix})
	\begin{equation}\label{eq:mu_xs_bounded}
	\left\|\begin{bmatrix}
	\mu \\ \tilde{x}_s 
	\end{bmatrix}\right\|_\infty
	\leq \gamma \cdot
	\left\|\Fc\right\|_\infty.
	\end{equation}
	
	Now we continue to prove that the estimation of unstable states $\tilde{x}_u$ are resilient.
	Rewrite the optimization problem \eqref{pb:resilient_LASSO} as 
	\begin{align*}
	\underset{{\tilde{x}},\ \mu}{\text{minimize}}&\quad \frac{1}{2} 
	\begin{bmatrix}
	\mu \\
	\Nc H \tilde{x}
	\end{bmatrix}^{'} \Wc
	\begin{bmatrix}
	\mu \\
	\Nc H \tilde{x}
	\end{bmatrix} + \gamma\left\|{Y}-\mu-H \tilde{x}\right\|_1 
	\end{align*}
	where the time index is omitted for notation simplicity.
	Consider the 1-norm term in the objective function:
	\begin{align*}
	&\left\| {Y}-\mu-H \tilde{x} \right\|_1
	=\sum_{i=1}^{m} 
	\left\|\eta_{i,u}-\mu_{i,u}-(H_{uu,i} \tilde{x}_u + H_{us,i} \tilde{x}_s) \right\|_1 
	+ \sum_{i=1}^{m} \left\|\eta_{i,s}-\mu_{i,s}- H_{ss,i} \tilde{x}_s \right\|_1 
	\end{align*}
	where $\eta_{i,u}, \mu_{i,u}$ is the vector composed of first $n_u$ element of $\eta_{i}, \mu_{i}$ and 
	$\eta_{i,s}, \mu_{i,s}$ is the vector composed of last $n_s$ element of $\eta_{i}, \mu_{i}$.
	Suppose that $\mu$ and $\tilde{x}_s$ have taken the value of optimal solution $\mu^*, \tilde{x}_s^*$, it is sufficient to minimize the following :
	\begin{align}\label{pb:1-norm_min}
	\min_{\tilde{x}_u} \sum_{i=1}^{m} \left\|\eta_{i,u}-\mu^*_{i,u}- H_{us,i} \tilde{x}^*_s - H_{uu,i} \tilde{x}_u \right\|_1  .
	\end{align}
	Define $\xi_i\triangleq \eta_{i,u}-\mu^*_{i,u}- H_{us,i} \tilde{x}^*_s $ and recall $[\cdot]_j$ is the $j$-th entry of a vector. The objective function in (\ref{pb:1-norm_min}) can be written as 
	\begin{align}
	&\sum_{i=1}^{m}\sum_{j=1}^{n_u} \left| [\xi_i]_j -[H_{uu,i} \tilde{x}_u]_j \right| 
	=\sum_{j=1}^{n_u}\sum_{i\in\Ec_j} \left| [\xi_i]_j -\tilde{x}_j \right| . \label{eq:solve_for_median}
	\end{align}
	where $\Ec_j$ is the index set of sensors that can observe state $j$ that is defined in \eqref{eq:def_Ec}.
	For each unstable state $j\in\Uc$, the minimizer $\tilde{x}_j$ of objective (\ref{eq:solve_for_median}) could be explicitly written as the median of all $[\xi_i]_j$ among $i\in\Ec_j$.
	
	Before proving that $\tilde{x}_j$ is bounded, let us define the following operator: $f_{i}: R \times R \times \cdots \times R \rightarrow R,$ such that $f_{i}\left(\alpha_{l}, l\in\{1,\cdots,L\}\right)$ equals to the $i$-th smallest element in the set $\left\{\alpha_{1}, \ldots, \alpha_{L}\right\} .$ For even number $i$, we further define 
	$$f_{\frac{i+1}{2}} = \left(f_{\frac{i}{2}} + f_{\frac{i}{2}+1}\right)/2.$$ 
	Thus, $f_{(L+1)/2}\left(\alpha_{l}, l\in\{1,\cdots,L\}\right)$ is the median number of set $\left\{\alpha_{1}, \ldots, \alpha_{L}\right\}$ and the solution to problem \eqref{pb:1-norm_min} is 
	\begin{align*}
	\tilde{x}_j = f_{(|\Ec_j|+1)/2}\left([\xi_i]_j, i\in\Ec_j\right),j\in\Uc .
	\end{align*}
	Define the uncorrupted data corresponding to sensor $i$ as $\eta^o_{i}=P_i\zeta^o_i$. Define $\xi^o_{i}$ correspondingly as $\xi^o_i\triangleq \eta^o_{i,u}-\mu^*_{i,u}- H_{us,i} x^*_s $.
	Recalling that the number of honest sensors and compromised sensors that can observe unstable state $j\in\Uc$ are $h_j$ and $c_j$, we have
	\begin{align}	
	f_{(h_j-c_j)}\left([\xi^o_i]_j, i\in\Ec_j\right) &\leq
	f_{(m+1)/2}\left([\xi_i]_j, i\in\Ec_j\right), \label{eq:x_u_leftbound}\\
	f_{(m+1)/2}\left([\xi_i]_j, i\in\Ec_j\right)&\leq 
	f_{2c_j}\left([\xi^o_i]_j, i\in\Ec_j\right) .  \label{eq:x_u_rightbound}
	\end{align}\	According to Lemma \ref{lm:cj<hj}, $h_j-c_j>0$ and $2c_j<h_j+c_j=|\Ec_j|$.
	As a result, according to (\ref{eq:x_u_leftbound}) and (\ref{eq:x_u_rightbound}), one obtains
	\begin{align}\label{eq:med_bound}
	\min \left\{ [\xi^o_i]_j, i\in\Ec_j \right\}\leq \tilde{x}_j\leq \max \left\{ [\xi^o_i]_j, i\in\Ec_j \right\},\ j\in\Uc .
	\end{align}
	Consider the following optimization problem where observation are not influenced by attack:
	\begin{align*}
	\underset{{\tilde{x}}^o,\mu^o}{\text{minimize}}&\quad \frac{1}{2} 
	\begin{bmatrix}
	\mu^o \\
	\Nc H \tilde{x}^o
	\end{bmatrix}^{'} \Wc
	\begin{bmatrix}
	\mu^o \\
	\Nc H \tilde{x}^o
	\end{bmatrix} + \gamma^o\left\|{Y}^o-\mu^o-H \tilde{x}^o\right\|_1 ,
	\end{align*}
	where ${Y}^o$ is composed of $P_i\zeta_i^o$. Denote the solution to this problem as ${\tilde{x}}^o,\mu^o$.
	According to Theorem \ref{th:no_attack}, by choosing 
	$$\gamma^o=	\left\|\Wc \begin{bmatrix}
	\left(I-GF\right)\epsilon^o(k) \\
	\Nc H \hat{x}^o(k)
	\end{bmatrix}\right\|_\ift, $$
	the solution coincides with Kalman estimation, i.e., $\tilde{x}^o(k)=\hat{x}^o(k)$.
	Similar to previous analysis, the solution $\tilde{x}^o$ satisfies 
	\begin{align}\label{eq:normal_solution}
	[\tilde{x}^o]_j=f_{(|\Ec_j|+1)/2}\left( [P_i\zeta_{i}^o-\mu^o_i]_j, i\in\Ec_j \right), \forall j\in\Uc\cup \Sc.
	\end{align}
	Combining \eqref{eq:med_bound} and \eqref{eq:normal_solution} leads to that, for every $j\in\Uc$,
	\begin{align*}
	\left|[\tilde{x}]_j-[\tilde{x}^o]_j\right| =\left|[\tilde{x}]_j-[\hat{x}^o]_j\right|
	\leq &
	\max_{i_1,i_2\in \Ec_j} \left| \left[P_{i_1} \zeta^o_{i_1}(k)\right]_j- \left[P_{i_2} \zeta^o_{i_2}(k)\right]_j \right| 
	+ \|\mu^*\|_\infty+ \|\mu^o\|_\infty\\
	\leq& \max_{i_1,i_2\in \Ec_j} \left| \left[P_{i_1} \zeta^o_{i_1}(k)\right]_j- \left[P_{i_2} \zeta^o_{i_2}(k)\right]_j \right| +(\gamma+\gamma^o)\|\Fc\|_\ift.
	\end{align*}
	Recall that $P_i\epsilon_{i}(k)=P_i \zeta_i (k)-H_ix(k)$. Since for all $i_1,i_2\in \Ec_j$, one obtains $[H_{i_1}x(k)]_j=[x(k)]_j=[H_{i_2}x(k)]_j,\forall k\in\Zb^+$. Thus, we have
	\begin{align*}
	&\max_{i_1,i_2\in \Ec_j} \left| \left[P_{i_1} \zeta^o_{i_1}(k)\right]_j- \left[P_{i_2} \zeta^o_{i_2}(k)\right]_j \right| =\max_{i_1,i_2\in \Ec_j} \left| \left[P_{i_1} \epsilon^o_{i_1}(k)\right]_j- \left[P_{i_2} \epsilon^o_{i_2}(k)\right]_j \right| ,
	\end{align*}
	whose variance is uniformly bounded for all $k$ according to Lemma \ref{lm:epsilon}. Similarly, $\gamma^o$ is also uniformly bounded for all $k$. 
	Recalling that $\tilde{x}_j,j\in\Sc$ is bounded from \eqref{eq:mu_xs_bounded} and the stable states in the absence of attack is always bounded, our estimation $\tilde{x}$ is secure according to Definition \ref{def:resi}. $\square$
\end{proof}

%\begin{proof}
%	%	Define $\tilde{M}\triangleq\tilde{P}\tilde{W}\tilde{P}{'}$.
%	Consider the KKT condition of problem (\ref{pb:lasso}) and one obtains $\tilde{M}^{-1}\mu=\gamma\cdot \sgn(\nu)$,	
%	%	 denote the dual variables for equation constraints as $\lambda=[\lambda_1{'},\cdots,\lambda_m{'}]{'}\in \Cb^{mn\times 1}$. 	
%	%	
%	%	\begin{align}
%	%		\tilde{M}^{-1}\mu - \lambda &= \mathbf{0} \label{eq:KKT1}\\
%	%		H{'}\lambda &= \mathbf{0} \label{eq:KKT2} \\
%	%		\gamma \cdot  \sgn(\nu) - \lambda &= \mathbf{0} \label{eq:KKT3} \\
%	%		{Y} - H \tilde{x} - \mu - \nu &= \mathbf{0}  \label{eq:KKT4}
%	%	\end{align}
%	where $\sgn(\cdot)$ is the subgradient of $\|\cdot\|_1$, i.e., for the $i$-th entry:
%	\begin{align*}
%		[\sgn(\nu)]_i=\partial |[\nu]_i|=
%		\left\{
%		\begin{array}{cc}
%			-1 ,& \ [\nu]_i<0 \\
%			1 , &\ [\nu]_i>0  \\
%			\{x|-1\leq x\leq 1\},& \ [\nu]_i=0 
%		\end{array}
%		\right. .
%	\end{align*}
%	The time index $(k)$ is omitted for notation conciseness.
%	Therefore, one obtains $\mu=\gamma\cdot \tilde{M}\sgn(\nu)$ and thus
%	$\|\mu\|_\ift\leq \gamma \left\|\tilde{M}\right\|_\ift$.
%	We proceed to prove that solution $\tilde{x}$ is bounded.
%	Notice that we are optimizing the following problem %(\ref{pb:LASSO_free}) 
%	\begin{align*}%\label{pb:LASSO_free}
%		\min _{\mu,\tilde{x}} \frac{1}{2} \mu{'} \tilde{W}^{-1} \mu+\gamma\left\|{Y}-\mu-H \tilde{x}\right\|_1 ,
%	\end{align*}
%	and suppose $\mu$ has taken the value of optimal solution $\mu^*$.
%	It is sufficient to minimize the following:
%	\begin{align}\label{pb:1-norm_min}
%		\min_{\tilde{x}} \sum_{i=1}^{m} \left\|P_i \zeta_{i}-\mu^*_{i}- H\tilde{x} \right\|_1  .
%	\end{align}
%	Notice that $P_i \zeta_{i}$ and $\mu^*_{i}$ are fixed known values.
%	Define $\xi_i\triangleq P_i \zeta_{i}-\mu^*_{i} $ and recall $[\cdot]_j$ is the $j$-th entry of a vector. The objective function in (\ref{pb:1-norm_min}) can be written as
%	\begin{align}
%		&\sum_{i=1}^{m}\sum_{j=1}^{n} \left| [\xi_i]_j -[H \tilde{x}]_j \right| 
%		=\sum_{j=1}^{n}\sum_{i\in\Ec_j} \left| [\xi_i]_j -[\tilde{x}]_j \right| . \label{eq:solve_for_median}
%	\end{align}
%	where $|\cdot|$ means absolute value and $\Ec_j$ is defined in \eqref{eq:def_Ec}. 
%	For each state index $j$, the minimizer $[\tilde{x}]_j$ of objective (\ref{eq:solve_for_median}) could be explicitly written as the median of all $[\xi_i]_j$ among $i\in\Ec_j$.
%	
%	Before proving that $[\tilde{x}]_j$ is bounded, let us define the following operator: $f_{i}: R \times R \times \cdots \times R \rightarrow R,$ such that $f_{i}\left(\alpha_{1}, \ldots, \alpha_{m}\right)$ equals to the $i$-th smallest element in the set $\left\{\alpha_{1}, \ldots, \alpha_{m}\right\} .$ For even number $m$, we further define 
%	$$f_{\frac{m+1}{2}} = \left(f_{\frac{m}{2}} + f_{\frac{m}{2}+1}\right)/2.$$ 
%	Thus, $f_{(m+1)/2}\left(\alpha_{1}, \ldots, \alpha_{m}\right)$ is the median number of set $\left\{\alpha_{1}, \ldots, \alpha_{m}\right\}$ and the solution to problem \eqref{pb:1-norm_min} is
%	\begin{align*}
%		[\tilde{x}]_j = f_{(m+1)/2}\left([\xi_i]_j, i\in\Ec_j\right).
%	\end{align*}
%	
%	Recalling the definition of $\zeta^o_{i}$ in \eqref{eq:def_zetare}, we define $\xi^o_{i}$ correspondingly as $\xi^o_i\triangleq P_i\zeta^o_{i}-\mu^*_{i} $.
%	Based on the definition of $h_j,c_j$ ($\Ic$ is omitted for notation simplicity), we have
%	\begin{align}	
%		f_{(h_j-c_j)}\left([\xi^o_i]_j, i\in\Ec_j\right) &\leq
%		f_{(m+1)/2}\left([\xi_i]_j, i\in\Ec_j\right), \label{eq:x_u_leftbound}\\
%		f_{(m+1)/2}\left([\xi_i]_j, i\in\Ec_j\right)&\leq 
%		f_{2c_j}\left([\xi^o_i]_j, i\in\Ec_j\right) .  \label{eq:x_u_rightbound}
%	\end{align}

%\end{proof}


	
%	\section*{ACKNOWLEDGMENT}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%	\end{thebibliography}
\bibliographystyle{IEEEtran}
%	\bibliographystyle{plain}
\bibliography{ref_zishuo}

\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
% on the last page of the document manually. It shortens
% the textheight of the last page by a suitable amount.
% This command does not take effect until the next page
% so it should come on the page before the last. Make
% sure that you do not shorten the textheight too much.


\end{document}
